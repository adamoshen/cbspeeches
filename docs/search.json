[{"path":"index.html","id":"analysis-of-central-bank-speeches","chapter":"Analysis of Central Bank Speeches","heading":"Analysis of Central Bank Speeches","text":"","code":""},{"path":"index.html","id":"data-stats","chapter":"Analysis of Central Bank Speeches","heading":"Data stats","text":"","code":""},{"path":"colophon.html","id":"colophon","chapter":"Colophon","heading":"Colophon","text":"","code":""},{"path":"colophon.html","id":"core-dependencies","chapter":"Colophon","heading":"Core dependencies","text":"Dependencies carry analysis.","code":"##  package     * version    date (UTC) lib source\n##  AzureAuth     1.3.3      2021-09-13 [1] RSPM\n##  AzureStor     3.7.0      2022-05-25 [1] RSPM\n##  cld2          1.2.5      2024-10-04 [1] RSPM\n##  dplyr         1.1.4      2023-11-17 [1] RSPM\n##  fs            1.6.5      2024-10-30 [1] RSPM\n##  gghighlight   0.4.1      2023-12-16 [1] RSPM (R 4.4.0)\n##  here          1.0.1      2020-12-13 [1] RSPM\n##  lubridate     1.9.4      2024-12-08 [1] RSPM\n##  pins          1.4.0      2024-10-07 [1] RSPM\n##  pinsqs        0.0.0.9000 2024-12-21 [1] Github (adamoshen/pinsqs@8d8aa38)\n##  purrr         1.0.2      2023-08-10 [1] RSPM\n##  readr         2.1.5      2024-01-10 [1] RSPM\n##  readxl        1.4.3      2023-07-06 [1] RSPM\n##  rstudioapi    0.17.1     2024-10-22 [1] RSPM\n##  stringi       1.8.4      2024-05-06 [1] RSPM\n##  stringr       1.5.1      2023-11-14 [1] RSPM\n##  tibble        3.2.1      2023-03-20 [1] RSPM\n##  tidytext      0.4.2      2024-04-10 [1] RSPM (R 4.4.0)\n##  topicmodels   0.2-17     2024-08-14 [1] RSPM\n##  udpipe        0.8.11     2023-01-06 [1] RSPM\n##  utf8          1.2.4      2023-10-22 [1] RSPM\n## \n##  [1] C:/Users/Adam/AppData/Local/R/win-library/4.4\n##  [2] C:/Program Files/R/R-4.4.2/library"},{"path":"colophon.html","id":"suggested-dependencies","chapter":"Colophon","heading":"Suggested dependencies","text":"Dependencies building book.","code":"##  package     * version date (UTC) lib source\n##  bookdown      0.41    2024-10-16 [1] RSPM\n##  bslib         0.8.0   2024-07-29 [1] RSPM\n##  desc          1.4.3   2023-12-10 [1] RSPM\n##  downlit       0.4.4   2024-06-10 [1] RSPM\n##  DT            0.33    2024-04-04 [1] RSPM (R 4.4.0)\n##  rmarkdown     2.29    2024-11-04 [1] RSPM\n##  servr         0.32    2024-10-04 [1] RSPM\n##  sessioninfo   1.2.2   2021-12-06 [1] RSPM\n## \n##  [1] C:/Users/Adam/AppData/Local/R/win-library/4.4\n##  [2] C:/Program Files/R/R-4.4.2/library"},{"path":"data-setup.html","id":"data-setup","chapter":"1 Data setup","heading":"1 Data setup","text":"chapter, speeches obtained Dropbox (csv format), minor adjustments\napplied text author fields, data re-saved processing \nsubsequent chapters.","code":""},{"path":"data-setup.html","id":"initialisation","chapter":"1 Data setup","heading":"1.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"data-setup.html","id":"minor-adjustments-to-raw-data","chapter":"1 Data setup","heading":"1.2 Minor adjustments to raw data","text":"Read speeches Dropbox:Perform minor adjustments:Rename column processed_text simply text.Remove time component dates.Perform normalization text author names ASCII form.Encode utf-8.Remove excessive spaces text author fields.Fix select author names consistency.","code":"\nspeeches <- read_csv(\"~/boc_speeches/lda/iteration_04/speeches_processed.csv\")\nspeeches <- speeches %>%\n  rename(text = processed_text) %>%\n  mutate(\n    date = as_date(date),\n    text = stringi::stri_trans_general(text, \"Greek-Latin\"),\n    text = stringi::stri_trans_general(text, \"Latin-ASCII\"),\n    text = utf8::as_utf8(text),\n    text = str_squish(text),\n    author = stringi::stri_trans_general(author, \"Greek-Latin\"),\n    author = stringi::stri_trans_general(author, \"Latin-ASCII\"),\n    author = utf8::as_utf8(author),\n    author = str_squish(author)\n  ) %>%\n  mutate(\n    author = str_replace_all(author, \"Angelovska-Bezoska\", \"Angelovska-Bezhoska\"),\n    author = str_replace_all(author, \"Angelovska Bezhoska\", \"Angelovska-Bezhoska\"),\n    text = str_replace_all(text, \"Angelovska-Bezoska\", \"Angelovska-Bezhoska\"),\n    text = str_replace_all(text, \"Angelovska Bezhoska\", \"Angelovska-Bezhoska\")\n  )"},{"path":"data-setup.html","id":"save-the-data","chapter":"1 Data setup","heading":"1.3 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-raw\",\n    title = \"speeches from dropbox with minor tweaks\"\n  )"},{"path":"identifying-the-country-from-the-text.html","id":"identifying-the-country-from-the-text","chapter":"2 Identifying the country from the text","heading":"2 Identifying the country from the text","text":"chapter documents extraction institution giving speech. applicable, \ncountry associated institution can identified.","code":""},{"path":"identifying-the-country-from-the-text.html","id":"initialisation-1","chapter":"2 Identifying the country from the text","heading":"2.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(cld2)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"identifying-the-country-from-the-text.html","id":"load-the-data","chapter":"2 Identifying the country from the text","heading":"2.2 Load the data","text":"","code":"\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-raw\")"},{"path":"identifying-the-country-from-the-text.html","id":"perform-language-detection","chapter":"2 Identifying the country from the text","heading":"2.3 Perform language detection","text":"Speeches dominant language English, removed. 18,827 speeches, 18,813\n(99.93%) English 14 (0.7%) English.","code":"\nspeeches <- speeches %>%\n  mutate(lang_cld2 = detect_language(text)) %>%\n  filter(lang_cld2 == \"en\") %>%\n  select(-lang_cld2)"},{"path":"identifying-the-country-from-the-text.html","id":"get-country","chapter":"2 Identifying the country from the text","heading":"2.4 Get country","text":"identification speech countries can briefly summarised follows:Extract institution name regex patterns.unable extract anything, extracted institution incorrect, affiliation \nauthor manually identified Google-ing.Normalise central bank names according format listed \nBIS website.Using list, identify country bank name.method chosen instead looking mentions country names first sentence \nspeech many instances meeting location different country \naffiliation author.","code":""},{"path":"identifying-the-country-from-the-text.html","id":"extract-institution-by-regex-patterns","chapter":"2 Identifying the country from the text","heading":"2.4.1 Extract institution by regex patterns","text":"institutions/organizations extracted looking general pattern :\n[position] (|) [institution name] within first sentence speech. attempt \nextraction institution/organization follows:","code":"\nextract_pattern1 <- \"(?<=(?:Board of Governors|Governing Board|Executive Board|Chief Executive Officer) of the )[^[:punct:]]+\"\nextract_pattern2 <- \"(?<=(?:Governor|President|Chairman|Director|Executive|Manager|Directorate) of the )[^[:punct:]]+\"\nextract_pattern3 <- \"(?<=Governor of )[^[:punct:]]+\" # for Philippines\nextract_pattern4 <- \"(?:Central|Reserve) Bank of (?:[:upper:][:lower:]+\\\\s?)+\"\nextract_pattern5 <- \"Bank of (?:[:upper:][:lower:]+\\\\s?)+\"\nextract_pattern6 <- \"(?i)National Bank of Serbia|Swiss National Bank|Hong Kong Monetary Authority|Monetary Authority of Singapore|Banco de Espana|Banco de Portugal|Banco de Mexico|South African Reserve Bank|Sveriges Riksbank|Oesterreichische Nationalbank\"\nextract_pattern7 <- \"Federal Reserve System\"\nextract_pattern8 <- \"(?i)Bank of [:alpha:]+\"\n\nspeeches <- speeches %>%\n  mutate(\n    # Remove periods after salutations, initials, and credentials\n    text = str_remove_all(text, \"(?<=Mr|Ms|Mrs|PhD|Dr|Dott|Prof|Jr|Sig|\\\\bp|\\\\bm|\\\\ba|\\\\bh|\\\\bc|\\\\bmult|vs|[A-Z0-9])\\\\.\"),\n    text = str_replace_all(text, \"Member Board of Governors\", \"Member of the Board of Governors\"),\n    text = str_replace_all(text, \"Govenor\", \"Governor\"),\n    # Extract first sentence before looking for patterns.\n    first_sentence = str_extract(text, \"^[^.]+\\\\.\"),\n    institution = str_extract(first_sentence, extract_pattern1),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern2), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern3), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern4), institution),\n    institution = if_else(institution == \"People\", \"The People's Bank of China\", institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern5), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern6), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern7), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern8), institution)\n  )"},{"path":"identifying-the-country-from-the-text.html","id":"fill-missingincorrect-institutions","chapter":"2 Identifying the country from the text","heading":"2.4.2 Fill missing/incorrect institutions","text":"extraction failed incorrect (determined looking institution values NA\nvalues low frequencies), speeches' institutions/organizations \nmanually determined Google-ing author speech. information stored \ninst/data-misc/author_affiliations.xlsx. data updated according spreadsheet (\napplicable).Two speeches remained missing values author institution. missing values \nfilled follows:","code":"\nauthor_affiliations <- read_xlsx(here::here(\"inst\", \"data-misc\", \"author_affiliations.xlsx\"))\n\nspeeches <- speeches %>%\n  rows_update(author_affiliations, by=\"author\")\nmissing_info <- tribble(\n  ~doc, ~author, ~institution,\n  \"r180725i\", \"Pablo Hernandez de Cos\", \"Bank of Spain\",\n  \"r180810b\", \"Jorgovanka Tabakovic\", \"National Bank of Serbia\"\n)\n\nspeeches <- speeches %>%\n  rows_update(missing_info, by=\"doc\")"},{"path":"identifying-the-country-from-the-text.html","id":"normalise-institution-names","chapter":"2 Identifying the country from the text","heading":"2.4.3 Normalise institution names","text":"list banks official names BIS website\ndownloaded stored inst/data-misc/bank_list.xlsx. extracted institution names \nprevious step normalised match names list. Additional organizations \nadded, BIS (Bank International Settlements) ECB (European Central Bank). US\nFederal Reserves associated common bank name Federal Reserve Bank.regex patterns , one may notice institution names contain typos, extracted\ndirectly speech text. Examples include Italy Italty Latvia Lativa. may\nimportant keep mind cleaning text later step.","code":"\nspeeches <- speeches %>%\n  mutate(\n    institution = str_squish(institution),\n    institution = case_when(\n      str_detect(institution, \"Federal Reserve|Atlanta|Chicago|Kansas City|New York|Saint Louis|San Francisco|America|BANK of NEW\") ~ \"Federal Reserve Bank\",\n      str_detect(institution, \"European Central Bank\") ~ \"European Central Bank\",\n      str_detect(institution, \"ECB\") ~ \"European Central Bank\",\n      str_detect(institution, \"Mauritius\") ~ \"Bank of Mauritius\",\n      str_detect(institution, \"Bundesbank\") ~ \"Deutsche Bundesbank\",\n      str_detect(institution, \"Italy|Italty\") ~ \"Bank of Italy\",\n      str_detect(institution, \"France\") ~ \"Bank of France\",\n      str_detect(institution, \"Japan\") ~ \"Bank of Japan\",\n      str_detect(institution, \"Korea\") ~ \"Bank of Korea\",\n      str_detect(institution, \"Bank of Papua New Guinea\") ~ \"Bank of Papua New Guinea\",\n      str_detect(institution, \"Bank of PNG\") ~ \"Bank of Papua New Guinea\",\n      str_detect(institution, \"(?i)Mexico\") ~ \"Bank of Mexico\",\n      str_detect(institution, \"China\") ~ \"The People's Bank of China\",\n      str_detect(institution, \"Ireland\") ~ \"Central Bank of Ireland\",\n      str_detect(institution, \"(?i)Portugal\") ~ \"Banco de Portugal\",\n      str_detect(institution, \"Bosnia|Herzegovina\") ~ \"Central Bank of Bosnia and Herzegovina\",\n      str_detect(institution, \"Romania\") ~ \"National Bank of Romania\",\n      str_detect(institution, \"Malaysia\") ~ \"Central Bank of Malaysia\",\n      str_detect(institution, \"Sierra Leone\") ~ \"Bank of Sierra Leone\",\n      str_detect(institution, \"Thailand\") ~ \"Bank of Thailand\",\n      str_detect(institution, \"(?i)Uganda\") ~ \"Bank of Uganda\",\n      str_detect(institution, \"Slovenia\") ~ \"Bank of Slovenia\",\n      str_detect(institution, \"Banka Slovenije\") ~ \"Bank of Slovenia\",\n      str_detect(institution, \"Bangko|Philippine|\\\\bBSP\\\\b\") ~ \"Central Bank of the Philippines (Bangko Sentral ng Pilipinas)\",\n      str_detect(institution, \"(?i)Riksbank\") ~ \"Sveriges Riksbank\",\n      str_detect(institution, \"Sweden|Swedish\") ~ \"Sveriges Riksbank\",\n      str_detect(institution, \"Riskbank|Risksbank\") ~ \"Sveriges Riksbank\",\n      str_detect(institution, \"Swiss\") ~ \"Swiss National Bank\",\n      str_detect(institution, \"Austria|Oesterreichische\") ~ \"Oesterreichische Nationalbank, the Austrian Central Bank\",\n      str_detect(institution, \"Norges|Norwegian\") ~ \"Central Bank of Norway\",\n      str_detect(institution, \"Denmark|Danmarks\") ~ \"Danmarks Nationalbank\",\n      str_detect(institution, \"Nederlandsche|Netherlands|Nederlandse\") ~ \"De Nederlandsche Bank\",\n      str_detect(institution, \"Macedonia\") ~ \"National Bank of the Republic of North Macedonia\",\n      str_detect(institution, \"Spain\") ~ \"Bank of Spain\",\n      str_detect(institution, \"Espana\") ~ \"Bank of Spain\",\n      str_detect(institution, \"(?i)Canada\") ~ \"Bank of Canada\",\n      str_detect(institution, \"(?i)Serbia\") ~ \"National Bank of Serbia\",\n      str_detect(institution, \"Hong Kong\") ~ \"Hong Kong Monetary Authority\",\n      str_detect(institution, \"India\") ~ \"Reserve Bank of India\",\n      str_detect(institution, \"Bangladesh\") ~ \"Bangladesh Bank\",\n      str_detect(institution, \"Indonesia\") ~ \"Bank Indonesia\",\n      str_detect(institution, \"Algeria\") ~ \"Bank of Algeria\",\n      str_detect(institution, \"Pakistan\") ~ \"State Bank of Pakistan\",\n      str_detect(institution, \"England\") ~ \"Bank of England\",\n      str_detect(institution, \"Finland\") ~ \"Bank of Finland\",\n      str_detect(institution, \"Suomen Pankki\") ~ \"Bank of Finland\",\n      str_detect(institution, \"(?i)Australia\") ~ \"Reserve Bank of Australia\",\n      str_detect(institution, \"Bahrain\") ~ \"Central Bank of Bahrain\",\n      str_detect(institution, \"Barbados\") ~ \"Central Bank of Barbados\",\n      str_detect(institution, \"Bahamas\") ~ \"Central Bank of The Bahamas\",\n      str_detect(institution, \"Belgium\") ~ \"National Bank of Belgium\",\n      str_detect(institution, \"(?i)Botswana\") ~ \"Bank of Botswana\",\n      str_detect(institution, \"Carribean\") ~ \"Eastern Caribbean Central Bank\",\n      str_detect(institution, \"(?i)Cambodia\") ~ \"National Bank of Cambodia\",\n      str_detect(institution, \"Chile\") ~ \"Central Bank of Chile\",\n      str_detect(institution, \"Columbia\") ~ \"Central Bank of Colombia\",\n      str_detect(institution, \"Croatia|Croation\") ~ \"Croatian National Bank\",\n      str_detect(institution, \"Curacao\") ~ \"Central Bank of Curacao and Sint Maarten\",\n      str_detect(institution, \"Cyprus\") ~ \"Central Bank of Cyprus\",\n      str_detect(institution, \"Czech\") ~ \"Czech National Bank\",\n      str_detect(institution, \"Ecuador\") ~ \"Central Bank of Ecuador\",\n      str_detect(institution, \"Eesti Pank\") ~ \"Bank of Estonia\",\n      str_detect(institution, \"(?i)Fiji\") ~ \"Reserve Bank of Fiji\",\n      str_detect(institution, \"Gambia\") ~ \"Central Bank of The Gambia\",\n      str_detect(institution, \"(?i)Ghana\") ~ \"Bank of Ghana\",\n      str_detect(institution, \"Greece\") ~ \"Bank of Greece\",\n      str_detect(institution, \"Guatemala\") ~ \"Bank of Guatemala\",\n      str_detect(institution, \"Hellenic\") ~ \"Bank of Greece\",\n      str_detect(institution, \"Iceland\") ~ \"Central Bank of Iceland\",\n      str_detect(institution, \"Kenya\") ~ \"Central Bank of Kenya\",\n      str_detect(institution, \"Kosovo\") ~ \"Central Bank of the Republic of Kosovo\",\n      str_detect(institution, \"Kuwait\") ~ \"Central Bank of Kuwait\",\n      str_detect(institution, \"Lativa\") ~ \"Bank of Latvia\",\n      str_detect(institution, \"Lithuania\") ~ \"Bank of Lithuania\",\n      str_detect(institution, \"Luxembourg\") ~ \"Central Bank of Luxembourg\",\n      str_detect(institution, \"Malawi\") ~ \"Reserve Bank of Malawi\",\n      str_detect(institution, \"Malta\") ~ \"Central Bank of Malta\",\n      str_detect(institution, \"Mozambique\") ~ \"Bank of Mozambique\",\n      str_detect(institution, \"Bank of Al\\\\b|Bank Al\\\\b|Al-Maghrib|Morocco\") ~ \"Bank Al-Maghrib (Central Bank of Morocco)\",\n      str_detect(institution, \"Nepal\") ~ \"Central Bank of Nepal (Nepal Rastra Bank)\",\n      str_detect(institution, \"New Zealand\") ~ \"Reserve Bank of New Zealand\",\n      str_detect(institution, \"Poland|Polski\") ~ \"Narodowy Bank Polski\",\n      str_detect(institution, \"Russia\") ~ \"Central Bank of the Russian Federation\",\n      str_detect(institution, \"Saudi\") ~ \"Saudi Central Bank\",\n      str_detect(institution, \"Seychelles\") ~ \"Central Bank of Seychelles\",\n      str_detect(institution, \"Singapore\") ~ \"Monetary Authority of Singapore\",\n      str_detect(institution, \"Slovakia|Slovenska\") ~ \"National Bank of Slovakia\",\n      str_detect(institution, \"Solomon Islands\") ~ \"Central Bank of Solomon Islands\",\n      str_detect(institution, \"South Africa\") ~ \"South African Reserve Bank\",\n      str_detect(institution, \"Ceylon\") ~ \"Central Bank of Sri Lanka\",\n      str_detect(institution, \"Swaziland|Eswatini\") ~ \"The Central Bank of Eswatini\",\n      str_detect(institution, \"Trinidad\") ~ \"Central Bank of Trinidad and Tobago\",\n      str_detect(institution, \"Tunisia\") ~ \"Central Bank of Tunisia\",\n      str_detect(institution, \"Turkiye|Turkey\") ~ \"Central Bank of the Republic of Turkiye\",\n      str_detect(institution, \"Emirates|UAE\") ~ \"Central Bank of the United Arab Emirates\",\n      str_detect(institution, \"Ukraine\") ~ \"National Bank of Ukraine\",\n      str_detect(institution, \"(?i)Zambia\") ~ \"Bank of Zambia\",\n      str_detect(institution, \"Bank for International Settlements|\\\\bBIS\\\\b\") ~ \"Bank for International Settlements\",\n      str_detect(institution, \"\\\\bBSC\\\\b\") ~ \"Banking Supervision Committee\",\n      str_detect(institution, \"Basel\") ~ \"Basel Committee\",\n      .default = institution\n    )\n  )"},{"path":"identifying-the-country-from-the-text.html","id":"get-country-from-institution-names","chapter":"2 Identifying the country from the text","heading":"2.4.4 Get country from institution names","text":"list banks, can associate speech country performing join.","code":"\nbank_list <- read_xlsx(here::here(\"inst\", \"data-misc\", \"bank_list.xlsx\"))\n\nspeeches <- speeches %>%\n  left_join(bank_list, by=\"institution\")"},{"path":"identifying-the-country-from-the-text.html","id":"save-the-data-1","chapter":"2 Identifying the country from the text","heading":"2.5 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-with-country\",\n    title = \"speeches with institutions and countries\"\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"cleaning-text-for-g7-countries","chapter":"3 Cleaning text for G7 countries","heading":"3 Cleaning text for G7 countries","text":"chapter documents cleaning text speeches given G7 country.","code":""},{"path":"cleaning-text-for-g7-countries.html","id":"initialisation-2","chapter":"3 Cleaning text for G7 countries","heading":"3.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"cleaning-text-for-g7-countries.html","id":"filter-speeches-to-g7-countries","chapter":"3 Cleaning text for G7 countries","heading":"3.2 Filter speeches to G7 countries","text":"","code":"\ng7_members <- c(\"Canada\", \"France\", \"Germany\", \"Italy\", \"Japan\", \"United Kingdom\", \"United States\")\n\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-with-country\") %>%\n  filter(country %in% g7_members)"},{"path":"cleaning-text-for-g7-countries.html","id":"fix-one-date","chapter":"3 Cleaning text for G7 countries","heading":"3.3 Fix one date","text":"one speech whose date December 2023, December 2024, corpus goes\nJanuary 2024.","code":"\ndata_update <- tribble(\n  ~doc, ~date,\n  \"r240109a\", ymd(\"2023-12-08\")\n)\n\nspeeches <- speeches %>%\n  rows_update(data_update, by=\"doc\")"},{"path":"cleaning-text-for-g7-countries.html","id":"repairs-and-removals","chapter":"3 Cleaning text for G7 countries","heading":"3.4 Repairs and removals","text":"","code":""},{"path":"cleaning-text-for-g7-countries.html","id":"remove-introductions","chapter":"3 Cleaning text for G7 countries","heading":"3.4.1 Remove introductions","text":"introductory remarks speech removed using pattern previously used \nidentify first sentence speech.\"Introduction\" headers also removed, identified presence word \"Introduction\"\ntitle case, followed another word title case.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove(text, pattern=\"^[^.]+\\\\.\"),\n    text = str_squish(text)\n  )\nspeeches <- speeches %>%\n  mutate(text = str_remove(text, \"Introduction (?=[:upper:])\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-references-section","chapter":"3 Cleaning text for G7 countries","heading":"3.4.2 Remove references section","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(?<=[:punct:]|[:digit:]) References:? .+$\"),\n    text = str_remove_all(text, \"References (?=[:upper:]).+$\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"repair-typos","chapter":"3 Cleaning text for G7 countries","heading":"3.4.3 Repair typos","text":"mentioned section normalising institution names, \ncountry names incorrectly entered require repair. G7 countries, Italy \none affected.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"Italty\", \"Italy\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-own-institution-and-country-names","chapter":"3 Cleaning text for G7 countries","heading":"3.4.4 Remove own institution and country names","text":"greater interest central bank mentions another central bank another country.\nTherefore, self-mentions bank, country, inhabitants removed. example, \nCanada, words remove include: Bank Canada, Canada, Canada's, Canadian. \nremoval patterns corresponding bank stored \ninst/data-misc/bank_country_regex_patterns.csv.bank_country_regex_patterns.csv file read using read_delim() rather read_csv()\nfile contains pre-escaped regex strings, , escape_backslash = TRUE required.","code":"\nbank_country_regex_patterns <- read_delim(\n  here::here(\"inst\", \"data-misc\", \"bank_country_regex_patterns.csv\"),\n  delim=\",\", escape_backslash=TRUE\n) %>%\n  filter(country %in% g7_members) %>%\n  select(country, regex_pattern)\n\nspeeches <- speeches %>%\n  left_join(bank_country_regex_patterns, by=\"country\") %>%\n  mutate(text = str_remove_all(text, regex_pattern)) %>%\n  select(-regex_pattern)"},{"path":"cleaning-text-for-g7-countries.html","id":"general-cleaning","chapter":"3 Cleaning text for G7 countries","heading":"3.5 General cleaning","text":"","code":""},{"path":"cleaning-text-for-g7-countries.html","id":"normalisaion-of-covid-related-terms","chapter":"3 Cleaning text for G7 countries","heading":"3.5.1 Normalisaion of COVID related terms","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)COVID|COVID19|COVID-19|coronavirus\", \"COVID\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"normalisation-of-select-ngrams-into-acronyms","chapter":"3 Cleaning text for G7 countries","heading":"3.5.2 Normalisation of select ngrams into acronyms","text":"\"Central Bank Digital Currency\" particular 4-gram interest can converted \nabbreviated form.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)Central Bank Digital Currency\", \"CBDC\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-non-ascii-characters-emails-social-media-handles-and-links","chapter":"3 Cleaning text for G7 countries","heading":"3.5.3 Remove non-ascii characters, emails, social media handles, and links","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"[:^ascii:]\"),\n    text = str_remove_all(text, \"([[:alnum:]_.\\\\-]+)?@[[:alnum:]_.\\\\-]+\"),\n    text = str_remove_all(text, \"https?://\\\\S+\"),\n    text = str_remove_all(text, \"www\\\\.\\\\S+\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"removereplace-strayexcessive-punctuation","chapter":"3 Cleaning text for G7 countries","heading":"3.5.4 Remove/replace stray/excessive punctuation","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(\\\\* )+\"),\n    text = str_replace_all(text, \"\\\\?|!\", \".\"),\n    text = str_remove_all(text, \",\"),\n    text = str_remove_all(text, \"\\\"\"),\n    text = str_replace_all(text, \"'{2,}\", \"'\"),\n    text = str_remove_all(text, \"\\\\B'(?=[:alpha:])\"),\n    text = str_remove_all(text, \"(?<=[:alpha:])'\\\\B\"),\n    text = str_remove_all(text, \"\\\\B'\\\\B\"),\n    text = str_replace_all(text, \"\\\\.{3}\", \".\"),\n    text = str_remove_all(text, \" \\\\. \"),\n    text = str_remove_all(text, \"-\"),\n    text = str_remove_all(text, \"_\"),\n    text = str_remove_all(text, \"\\\\(|\\\\)|\\\\{|\\\\}|\\\\[|\\\\]|\\\\||;|:|\\\\+\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-numerical-quantities","chapter":"3 Cleaning text for G7 countries","heading":"3.5.5 Remove numerical quantities","text":"included dollar signs, percent signs, punctuation separated numbers, whole numbers.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"\\\\$\"),\n    text = str_remove_all(text, \"%\"),\n    text = str_remove_all(text, \"[:digit:]+([.,]+[:digit:]+)*\"),\n    text = str_remove_all(text, \"[:digit:]\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-stray-letters","chapter":"3 Cleaning text for G7 countries","heading":"3.5.6 Remove stray letters","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"\\\\b[A-Za-z]\\\\b\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"final-squish","chapter":"3 Cleaning text for G7 countries","heading":"3.5.7 Final squish","text":"Excessive whitespace resulting previous removals/replacements removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_squish(text))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-unneeded-columns","chapter":"3 Cleaning text for G7 countries","heading":"3.5.8 Remove unneeded columns","text":"","code":"\nspeeches <- speeches %>%\n  select(-first_sentence)"},{"path":"cleaning-text-for-g7-countries.html","id":"save-the-data-2","chapter":"3 Cleaning text for G7 countries","heading":"3.6 Save the data","text":"Writing data pin board:Make separate copy metadata well:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g7-cleaned\",\n    title = \"speeches for g7 countries, cleaned\"\n  )\nspeeches_metadata <- speeches %>%\n  select(doc, date, institution, country)\n\nspeeches_board %>%\n  pin_qsave(\n    speeches_metadata,\n    \"speeches-g7-metadata\",\n    title = \"metadata for g7 speeches\"\n  )"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"identifying-important-bigrams-and-trigrams","chapter":"4 Identifying important bigrams and trigrams","heading":"4 Identifying important bigrams and trigrams","text":"chapter documents identification important bigrams trigrams following procedure\ndescribed Stephen Hansen, Michael McMahon, Andrea Prat1 John S. Justeson Slava M. Katz2.","code":""},{"path":"identifying-important-bigrams-and-trigrams.html","id":"initialisation-3","chapter":"4 Identifying important bigrams and trigrams","heading":"4.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(udpipe)\nlibrary(magrittr)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"tokenise-the-text-for-pos-tagging","chapter":"4 Identifying important bigrams and trigrams","heading":"4.2 Tokenise the text for POS-tagging","text":"text first tokenised sentences order create sentence identifier within\ndocuments. required later looking tag sequences, tag sequences span across\nsentences considered.text cast lowercase just yet, appeared affect tagging.Creating quick checkpoint:","code":"\nspeech_tokens <- speeches_board %>%\n  pin_qread(\"speeches-g7-cleaned\") %>%\n  select(doc, text) %>%\n  unnest_sentences(output=sentence, input=text, to_lower=FALSE) %>%\n  group_by(doc) %>%\n  mutate(sentence_id = 1:n()) %>%\n  ungroup() %>%\n  unnest_tokens(output=token, input=sentence, to_lower=FALSE)\nspeeches_board %>%\n  pin_qsave(\n    speech_tokens,\n    \"speeches-g7-tokens\",\n    title = \"tokens of speeches for g7 countries, cleaned\"\n  )"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"perform-the-pos-tagging","chapter":"4 Identifying important bigrams and trigrams","heading":"4.3 Perform the POS tagging","text":"","code":""},{"path":"identifying-important-bigrams-and-trigrams.html","id":"download-annotated-model","chapter":"4 Identifying important bigrams and trigrams","heading":"4.3.1 Download annotated model","text":"model used tagging \nUniversal Dependencies English GUM corpus.\nmodel included inst/data-misc folder, can downloaded calling \nfollowing:downloaded model can loaded follows:","code":"\nudpipe_download_model(language=\"english-gum\", model_dir=here::here(\"inst\", \"data-misc\"))\nenglish_gum <- udpipe_load_model(file = here::here(\"inst\", \"data-misc\", \"english-gum-ud-2.5-191206.udpipe\"))"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"tagging","chapter":"4 Identifying important bigrams and trigrams","heading":"4.3.2 Tagging","text":"udpipe_annotate():tokenizer = \"vertical\" indicates supplied text already tokenised form \ndata frame.parser = \"none\" indicates dependency parsing need performed.trace = 5e5 prints progress update every 5e5 tokens.supplying tokenised data frame, resulting output number rows. \n, sentence identifier speech_tokens can easily re-bound tagged tokens.Creating quick checkpoint:","code":"\ntags_gum <- speech_tokens %$%\n  udpipe_annotate(\n    object=english_gum, x=token, doc_id=doc,\n    tokenizer=\"vertical\", parser=\"none\", trace=5e5\n  ) %>%\n  as_tibble() %>%\n  select(doc_id, token, lemma, upos) %>%\n  rename(upos_gum = upos)\ntags_gum <- tags_gum %>%\n  bind_cols(\n    speech_tokens %>%\n      select(sentence_id)\n  ) %>%\n  select(doc_id, sentence_id, token, lemma, upos_gum)\nspeeches_board %>%\n  pin_qsave(\n    tags_gum,\n    \"gum-tagged-tokens-g7\",\n    title = \"gum tagged tokens of speeches for g7 countries\"\n  )"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"determine-bigrams-and-trigrams","chapter":"4 Identifying important bigrams and trigrams","heading":"4.4 Determine bigrams and trigrams","text":"Hansen, McMahon, Prat3, trigram sequences interest frequencies greater equal 50 :adjective - adjective - nounadjective - noun - nounnoun - adjective - nounnoun - noun - nounnoun - preposition - nounProper nouns treated nouns.Hansen, McMahon, Prat4, bigram sequences interest frequencies greater equal 100 :adjective - nounnoun - nounProper nouns treated nouns.","code":"\ntrigrams <- tags_gum %>%\n  select(-lemma) %>%\n  rename(token1=token, upos_gum1=upos_gum) %>%\n  group_by(doc_id, sentence_id) %>%\n  mutate(\n    token2 = lead(token1),\n    token3 = lead(token2),\n    upos_gum1 = if_else(upos_gum1 == \"PROPN\", \"NOUN\", upos_gum1),\n    upos_gum2 = lead(upos_gum1),\n    upos_gum3 = lead(upos_gum2)\n  ) %>%\n  ungroup() %>%\n  drop_na() %>%\n  select(token1, token2, token3, upos_gum1, upos_gum2, upos_gum3) %>%\n  unite(col=\"pos_pattern\", upos_gum1, upos_gum2, upos_gum3) %>%\n  filter(\n    str_detect(\n      pos_pattern,\n      \"ADJ_ADJ_NOUN|ADJ_NOUN_NOUN|NOUN_ADJ_NOUN|NOUN_NOUN_NOUN|NOUN_ADP_NOUN\"\n    )\n  ) %>%\n  count(token1, token2, token3, pos_pattern) %>%\n  filter(n >= 50) %>%\n  arrange(desc(n))\nbigrams <- tags_gum %>%\n  select(-lemma) %>%\n  rename(token1=token, upos_gum1=upos_gum) %>%\n  group_by(doc_id) %>%\n  mutate(\n    token2 = lead(token1),\n    upos_gum1 = if_else(upos_gum1 == \"PROPN\", \"NOUN\", upos_gum1),\n    upos_gum2 = lead(upos_gum1)\n  ) %>%\n  ungroup() %>%\n  drop_na() %>%\n  select(token1, token2, upos_gum1, upos_gum2) %>%\n  unite(col=\"pos_pattern\", upos_gum1, upos_gum2) %>%\n  filter(\n    str_detect(\n      pos_pattern,\n      \"ADJ_NOUN|NOUN_NOUN\"\n    )\n  ) %>%\n  count(token1, token2, pos_pattern) %>%\n  filter(n >= 100) %>%\n  arrange(desc(n))"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"prune-bigrams","chapter":"4 Identifying important bigrams and trigrams","heading":"4.4.1 Prune bigrams","text":"Bigrams whose frequencies fall required threshold consideration \nappearances trigrams removed. example, consider following n-gram counts:rising oil prices: 339falling oil prices: 275oil prices: 642Since bigram oil prices appears 642 - 339 - 275 = 28 times , meet\nbigram frequency threshold removed list bigrams.","code":"\ntrigram_token_counts <- trigrams %>%\n  select(token1, token2, token3, n)\n\nbigram_token_counts <- bigrams %>%\n  select(token1, token2, n)\n\nbigrams_to_remove <- bind_rows(\n  trigram_token_counts %>%\n    select(token1, token2, n) %>%\n    inner_join(bigram_token_counts, by=c(\"token1\", \"token2\"), suffix=c(\"_tri\", \"_bi\")\n  ),\n  trigram_token_counts %>%\n    select(token2, token3, n) %>%\n    rename(token1=token2, token2=token3) %>%\n    inner_join(bigram_token_counts, by=c(\"token1\", \"token2\"), suffix=c(\"_tri\", \"_bi\"))\n) %>%\n  group_by(token1, token2) %>%\n  summarise(\n    n_tri = sum(n_tri),\n    n_bi = unique(n_bi)\n  ) %>%\n  ungroup() %>%\n  mutate(n_diff = n_bi - n_tri) %>%\n  filter(n_diff < 100) %>%\n  select(token1, token2)\n\nbigrams <- anti_join(bigrams, bigrams_to_remove, by=c(\"token1\", \"token2\"))"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"save-the-data-3","chapter":"4 Identifying important bigrams and trigrams","heading":"4.5 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    trigrams,\n    \"gum-trigrams-g7\",\n    title = \"gum trigrams from g7 speeches\"\n  )\n\nspeeches_board %>%\n  pin_qsave(\n    bigrams,\n    \"gum-bigrams-g7\",\n    title = \"gum bigrams from g7 speeches\"\n  )"},{"path":"incorporating-the-found-n-grams.html","id":"incorporating-the-found-n-grams","chapter":"5 Incorporating the found n-grams","heading":"5 Incorporating the found n-grams","text":"chapter documents incorporation previously found n-grams speech text.","code":""},{"path":"incorporating-the-found-n-grams.html","id":"initialisation-4","chapter":"5 Incorporating the found n-grams","heading":"5.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-g7-cleaned\")\n\nbigrams <- speeches_board %>%\n  pin_qread(\"gum-bigrams-g7\")\n\ntrigrams <- speeches_board %>%\n  pin_qread(\"gum-trigrams-g7\")"},{"path":"incorporating-the-found-n-grams.html","id":"text-replacement","chapter":"5 Incorporating the found n-grams","heading":"5.2 Text replacement","text":"identified n-grams replaced text via regex. str_replace_all() function allows\nmultiple replacements supplying named vector whose names regex patterns whose\nvalues replacements. regex patterns used case insensitive underscores \nadded words end n-gram prevent stemming (later stage). \naddition, trigrams replaced text bigrams ensure longest n-gram \ncaptured.","code":"\ntrigram_replacements <- trigrams %>%\n  mutate(across(c(token1, token2, token3), str_to_lower)) %>%\n  distinct(token1, token2, token3) %>%\n  mutate(\n    pattern = str_c(\"(?i)\\\\b\", token1, \" \", token2, \" \", token3, \"\\\\b\"),\n    replacement = str_c(token1, \"_\", token2, \"_\", token3, \"_\")\n  ) %>%\n  pull(replacement, name=pattern)\n\nbigram_replacements <- bigrams %>%\n  mutate(across(c(token1, token2), str_to_lower)) %>%\n  distinct(token1, token2) %>%\n  mutate(\n    pattern = str_c(\"(?i)\\\\b\", token1, \" \", token2, \"\\\\b\"),\n    replacement = str_c(token1, \"_\", token2, \"_\")\n  ) %>%\n  pull(replacement, name=pattern)\n\nspeeches <- speeches %>%\n  mutate(\n    text = str_replace_all(text, trigram_replacements),\n    text = str_replace_all(text, bigram_replacements)\n  )"},{"path":"incorporating-the-found-n-grams.html","id":"save-the-data-4","chapter":"5 Incorporating the found n-grams","heading":"5.3 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g7-with-ngrams\",\n    title = \"speeches for g7 countries, with ngrams\"\n  )"},{"path":"final-pre-processing.html","id":"final-pre-processing","chapter":"6 Final pre-processing","heading":"6 Final pre-processing","text":"chapter documents final pre-processing steps text can transformed \nrequired document-term matrices term-document matrices.","code":""},{"path":"final-pre-processing.html","id":"initialisation-5","chapter":"6 Final pre-processing","heading":"6.1 Initialisation","text":"list stop words used derived Snowball stop word lexicon, negation\nterms removed. code used obtain stop word list can found\n.","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(SnowballC)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-g7-with-ngrams\")\nnonneg_snowball <- read_rds(here::here(\"inst\", \"data-misc\", \"nonneg_snowball.rds\"))"},{"path":"final-pre-processing.html","id":"pre-processing","chapter":"6 Final pre-processing","heading":"6.2 Pre-processing","text":"usual pre-processing steps performed, including:Unnesting tokens. Lowercasing occurs step.Removal non-negative stop words.Stemming words.final check performed verify stemmed tokens spaces empty\nstrings, can result unusable models downstream.Making quick checkpoint:","code":"\nspeeches <- speeches %>%\n  unnest_tokens(output=word, input=text) %>%\n  anti_join(nonneg_snowball, by=\"word\") %>%\n  mutate(wordstem = wordStem(word))\nspeeches %>%\n  filter(wordstem == \" \")\n\nspeeches %>%\n  filter(stringi::stri_isempty(wordstem))\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"processed-speeches-g7\",\n    title = \"processed speeches for g7 countries. ready for dtm/tdm conversion.\"\n  )"},{"path":"final-pre-processing.html","id":"create-document-term-matrix","chapter":"6 Final pre-processing","heading":"6.3 Create document-term matrix","text":"document-term matrix required topic models via {topicmodels} package.","code":"\nspeeches_dtm <- speeches %>%\n  count(doc, wordstem) %>%\n  cast_dtm(doc, wordstem, n)\nspeeches_board %>%\n  pin_qsave(\n    speeches_dtm,\n    \"speeches-g7-dtm\",\n    title = \"dtm of speeches for g7 countries\"\n  )"},{"path":"final-pre-processing.html","id":"create-term-document-matrix","chapter":"6 Final pre-processing","heading":"6.4 Create term-document matrix","text":"term-document matrix (plain matrix) required NMF models.","code":"\nspeeches_tdm <- speeches %>%\n  count(doc, wordstem) %>%\n  cast_tdm(wordstem, doc, n) %>%\n  as.matrix()\nspeeches_board %>%\n  pin_qsave(\n    speeches_tdm,\n    \"speeches-g7-tdm\",\n    title = \"tdm of speeches for g7 countries\"\n  )"},{"path":"explorations-with-nmf.html","id":"explorations-with-nmf","chapter":"7 Explorations with NMF","heading":"7 Explorations with NMF","text":"non-negative matrix factorization (NMF) files currently stored \ninst/NMFregress (GitHub). current state,\nNMFregress requires user specify either anchors. anchors \nparticularly interested , work needs done NMFregress order ensure\nusers can supply subset anchors, remaining anchors automatically\npopulated.sake moving forward proof concept, 50-topic NMF model fitted, \n40-topic NMF model fitted using anchors interest, remaining filled using\nanchors 50-topic model.","code":""},{"path":"explorations-with-nmf.html","id":"initialisation-6","chapter":"7 Explorations with NMF","heading":"7.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\nlibrary(gghighlight)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nfs::dir_ls(here::here(\"inst\", \"NMFregress\"), glob=\"*.R\") %>%\n  walk(source)\n\ntheme_set(theme_bw())\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")\n\nmodels_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-models\")"},{"path":"explorations-with-nmf.html","id":"model-fitting","chapter":"7 Explorations with NMF","heading":"7.2 Model fitting","text":"","code":""},{"path":"explorations-with-nmf.html","id":"fitting-the-50-topic-model","chapter":"7 Explorations with NMF","heading":"7.2.1 Fitting the 50-topic model","text":"following code used fit 50-topic NMF model.anchors can found calling nmf_output$anchors.","code":"\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-g7-tdm\")\n\nnmf_input <- create_input(speeches, vocab=rownames(speeches), topics=50)\nnmf_output <- solve_nmf(nmf_input)"},{"path":"explorations-with-nmf.html","id":"fitting-the-40-topic-model","chapter":"7 Explorations with NMF","heading":"7.2.2 Fitting the 40-topic model","text":"40-topic NMF model fitted using combination anchors interest anchors\nfound 50-topic NMF model previous step. Note since text \nterm-document matrix lowercased stemmed, supplied anchors also needed \nlowercased stemmed form.stemmed form word can obtained calling SnowballC::wordstem(\"word\").Fitting 40-topic NMF model:Creating checkpoint:","code":"\nanchors_of_interest <- c(\"basel\", \"cbdc\", \"ukrain\", \"covid\", \"brexit\")\nautofilled_anchors <- c(\n  \"inflat\", \"rate\", \"euro\", \"climat\", \"payment\", \"trade\", \"global\", \"model\", \"monetary_policy_\",\n  \"economi\", \"loan\", \"target\", \"market\", \"fund\", \"chang\", \"polici\", \"growth\", \"data\", \"percent\",\n  \"invest\", \"liquid\", \"consum\", \"system\", \"compani\", \"demand\", \"risk\", \"effect\", \"product\",\n  \"asset\", \"price\", \"firm\", \"pai\", \"account\", \"household\", \"insur\"\n)\ncustom_anchors <- c(anchors_of_interest, autofilled_anchors)\nnmf_input <- create_input(speeches, vocab=rownames(speeches), topics=40)\nnmf_output <- solve_nmf(nmf_input, user_anchors=custom_anchors)\nmodels_board %>%\n  pin_qsave(\n    nmf_output,\n    \"nmf-g7-k=40\",\n    title = \"40-topic nmf, g7, custom topics\"\n  )"},{"path":"explorations-with-nmf.html","id":"explorations","chapter":"7 Explorations with NMF","heading":"7.3 Explorations","text":"Loading required data:","code":"\nspeeches_metadata <- speeches_board %>%\n  pin_qread(\"speeches-g7-metadata\", version=\"20241207T163741Z-5783f\")"},{"path":"explorations-with-nmf.html","id":"pre-exploration-data-wrangling","chapter":"7 Explorations with NMF","heading":"7.3.1 Pre-exploration data wrangling","text":"Variables refer theta pertain document-topic matrix.First, document-topic proportions recovered NMF model.Next, document-topic proportions reunited speech metadata. document-topic proportions\naggregated averaged year-month produce monthly time series topic\nproportions.plotting, rather labelling topic anchor word, topic's top 10 words can used\ninstead.","code":"\nnormalised_theta <- nmf_output %>%\n  pluck(\"theta\") %>%\n  t() %>%\n  magrittr::divide_by(rowSums(.)) %>%\n  as_tibble(rownames = \"doc\") %>%\n  pivot_longer(-doc, names_to=\"anchor\", values_to=\"proportion\")\ndoc_dates <- speeches_metadata %>%\n  select(doc, country, date)\n\ntheta_dates <- inner_join(normalised_theta, doc_dates, by=\"doc\")\n\nsummarised_theta_by_month <- theta_dates %>%\n  mutate(\n    year = year(date),\n    month = month(date)\n  ) %>%\n  group_by(country, year, month, anchor) %>%\n  summarise(avg_proportion = mean(proportion)) %>%\n  ungroup() %>%\n  unite(\"date\", year, month, sep=\"-\") %>%\n  mutate(date = ym(date))\ntop_words <- print_top_words(nmf_output, n=10) %>%\n  map(str_flatten_comma)\n\nlabel_top_words <- top_words %>%\n  flatten_chr() %>%\n  str_c(nmf_output$anchors, \": \", .) %>%\n  set_names(nmf_output$anchors) %>%\n  as_labeller()"},{"path":"explorations-with-nmf.html","id":"plots","chapter":"7 Explorations with NMF","heading":"7.3.2 Plots","text":"finer view plots, open image new tab zoom desired!","code":"\nsummarised_theta_by_month %>%\n  filter(anchor %in% c(\"brexit\", \"cbdc\", \"covid\", \"ukrain\")) %>%\n  ggplot() +\n  geom_line(aes(x=date, y=avg_proportion, colour=country), alpha=0.4) +\n  facet_wrap(~ anchor, ncol=1, labeller=label_top_words) +\n  gghighlight(\n    max(avg_proportion, na.rm=TRUE) > 0.15, max_highlight=3L,\n    use_direct_label=FALSE, calculate_per_facet=TRUE\n  ) +\n  scale_x_date(breaks = \"2 years\", date_labels=\"%Y\") +\n  scale_color_manual(\n    values = palette.colors(7, palette=\"Tableau 10\"),\n    guide = guide_legend(nrow = 2)\n  ) +\n  labs(\n    x=\"Year\", y=\"Averaged topic proportions\",\n    subtitle=\"Only countries that reach an average topic proportion > 0.15 are highlighted\"\n  ) +\n  guides(colour = guide_legend(nrow = 2)) +\n  theme(legend.title=element_blank(), legend.position=\"bottom\")\nsummarised_theta_by_month %>%\n  filter(anchor %in% c(\"polici\", \"basel\", \"inflat\", \"monetary_policy_\")) %>%\n  ggplot() +\n  geom_line(aes(x=date, y=avg_proportion, colour=country), alpha=0.4) +\n  facet_wrap(~ anchor, ncol=1, labeller=label_top_words) +\n  gghighlight(\n    max(avg_proportion, na.rm=TRUE) > 0.20, max_highlight=3L,\n    use_direct_label=FALSE, calculate_per_facet=TRUE\n  ) +\n  scale_x_date(breaks = \"2 years\", date_labels=\"%Y\") +\n  scale_color_manual(\n    values = palette.colors(7, palette=\"Tableau 10\"),\n    guide = guide_legend(nrow = 2)\n  ) +\n  labs(\n    x=\"Year\", y=\"Averaged topic proportions\",\n    subtitle=\"Only countries that reach an average topic proportion > 0.20 are highlighted\"\n  ) +\n  theme(legend.title=element_blank(), legend.position=\"bottom\")"},{"path":"explorations-with-lda.html","id":"explorations-with-lda","chapter":"8 Explorations with LDA","heading":"8 Explorations with LDA","text":"","code":""},{"path":"explorations-with-lda.html","id":"initialisation-7","chapter":"8 Explorations with LDA","heading":"8.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(topicmodels)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\nlibrary(gghighlight)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nfs::dir_ls(here::here(\"inst\", \"NMFregress\"), glob=\"*.R\") %>%\n  walk(source)\n\ntheme_set(theme_bw())\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")\n\nmodels_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-models\")"},{"path":"explorations-with-lda.html","id":"model-fitting-1","chapter":"8 Explorations with LDA","heading":"8.2 Model fitting","text":"proof concept, LDA model fix values hyperparameters:K, number topics, set 40.alpha, homogeneity document-topic distributions, set 1/K=1/401/K \\,=\\, 1/401/K=1/40.delta, homogeneity topic-term distributions, set 0.1.Creating checkpoint:","code":"\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-g7-dtm\")\n\ngibbs_control <- list(\n  seed = 100,\n  verbose = 1L,\n  alpha = 1/40,\n  delta = 0.1,\n  iter = 500\n)\n\nlda_model <- LDA(\n  speeches,\n  k = 40,\n  method = \"Gibbs\",\n  control = gibbs_control\n)\nmodels_board %>%\n  pin_qsave(\n    lda_model,\n    \"lda-g7-k=40\",\n    title = \"40-topic lda, g7\"\n  )"},{"path":"explorations-with-lda.html","id":"explorations-1","chapter":"8 Explorations with LDA","heading":"8.3 Explorations","text":"","code":"\nspeeches_metadata <- speeches_board %>%\n  pin_qread(\"speeches-g7-metadata\", version=\"20241207T163741Z-5783f\")"},{"path":"explorations-with-lda.html","id":"pre-exploration-data-wrangling-1","chapter":"8 Explorations with LDA","heading":"8.3.1 Pre-exploration data wrangling","text":"NMF, variables refer theta pertain document-topic matrix. Note LDA\nmodels produced {topicmodels} refer matrix gamma.NMF, document-topic distribution first retrieved model reunited \ndocument metadata.Next, document-topic proportions aggregated averaged year-month produce monthly\ntime series topic proportions.plotting, without assigning names topic, topic's top 10 words can used instead.","code":"\ndtd <- lda_output %>%\n  tidy(matrix = \"gamma\") %>%\n  inner_join(speeches_metadata, by=c(\"document\" = \"doc\")) %>%\n  arrange(date, document, topic)\nsummarised_theta_by_month <- dtd %>%\n  mutate(\n    year = year(date),\n    month = month(date)\n  ) %>%\n  group_by(country, year, month, topic) %>%\n  summarise(avg_probability = mean(gamma)) %>%\n  ungroup() %>%\n  unite(\"date\", year, month, sep=\"-\") %>%\n  mutate(date = ym(date))\nttd <- lda_output %>%\n  tidy(matrix = \"beta\") %>%\n  arrange(topic, desc(beta))\n\ntop_words <- ttd %>%\n  select(-beta) %>%\n  group_split(topic) %>%\n  map(~ slice_head(.x, n=10)) %>%\n  map(~ pull(.x, term)) %>%\n  map(str_flatten_comma) %>%\n  set_names(1:40)\n\nlabel_top_words <- top_words %>%\n  flatten_chr() %>%\n  str_c(as.character(1:40), \": \", .) %>%\n  set_names(1:40) %>%\n  as_labeller()"},{"path":"explorations-with-lda.html","id":"plots-1","chapter":"8 Explorations with LDA","heading":"8.3.2 Plots","text":"finer view plots, open image new tab zoom desired!","code":"\nsummarised_theta_by_month %>%\n  filter(topic %in% c(21, 26, 34, 37)) %>%\n  ggplot() +\n  geom_line(aes(x=date, y=avg_probability, colour=country), alpha=0.4) +\n  facet_wrap(~ topic, ncol=1, labeller=label_top_words) +\n  gghighlight(max(avg_probability) > 0.4, calculate_per_facet=TRUE, use_direct_label=FALSE) +\n  scale_x_date(breaks = \"2 years\", date_labels=\"%Y\") +\n  scale_color_manual(\n    values = palette.colors(7, palette=\"Tableau 10\"),\n    guide = guide_legend(nrow = 2)\n  ) +\n  labs(\n    x=\"Year\", y=\"Averaged topic probabilities\",\n    subtitle=\"Only countries that reach an average topic probability > 0.40 are highlighted\"\n  ) +\n  theme(legend.title=element_blank(), legend.position=\"bottom\")\nsummarised_theta_by_month %>%\n  filter(topic %in% c(9, 21, 24)) %>%\n  ggplot() +\n  geom_line(aes(x=date, y=avg_probability, colour=country), alpha=0.4) +\n  facet_wrap(~ topic, ncol=1, labeller=label_top_words) +\n  gghighlight(max(avg_probability) > 0.4, calculate_per_facet=TRUE, use_direct_label=FALSE) +\n  scale_x_date(breaks = \"2 years\", date_labels=\"%Y\") +\n  scale_color_manual(\n    values = palette.colors(7, palette=\"Tableau 10\"),\n    guide = guide_legend(nrow = 2)\n  ) +\n  labs(x=\"Year\", y=\"Averaged topic probabilities\") +\n  theme(legend.title=element_blank(), legend.position=\"bottom\")\nsummarised_theta_by_month %>%\n  filter(topic %in% c(14, 8, 31)) %>%\n  ggplot() +\n  geom_line(aes(x=date, y=avg_probability, colour=country), alpha=0.4) +\n  facet_wrap(~ topic, ncol=1, labeller=label_top_words) +\n  gghighlight(max(avg_probability) > 0.4, calculate_per_facet=TRUE, use_direct_label=FALSE) +\n  scale_x_date(breaks = \"2 years\", date_labels=\"%Y\") +\n  scale_color_manual(\n    values = palette.colors(7, palette=\"Tableau 10\"),\n    guide = guide_legend(nrow = 2)\n  ) +\n  labs(\n    x=\"Year\", y=\"Averaged topic probabilities\",\n    subtitle=\"Only countries that reach an average topic probability > 0.40 are highlighted\"\n  ) +\n  theme(legend.title=element_blank(), legend.position=\"bottom\")"},{"path":"re-cleaning-the-g7-speeches.html","id":"re-cleaning-the-g7-speeches","chapter":"9 Re-cleaning the G7 speeches","heading":"9 Re-cleaning the G7 speeches","text":"G7 consists seven countries: Canada, France, Germany, Italy, Japan, United Kingdom, \nUnited States.results models produced proof concept section, cleaning G10\nG20 speeches, adjustments needed made cleaning G7 speeches. \nchapter's contents mostly identical \nCleaning text G7 countries, additions :careful removal introductory remarks section headers.generalised text cleaning function, clean_general(), found R/clean_by_country.R \ncleaning text speeches less problematic.Removal links start : http, https, www.Improved handling punctuation removal.Remove mentions slides, figures, graphs.Omitting removal stray letters.","code":""},{"path":"re-cleaning-the-g7-speeches.html","id":"initialisation-8","chapter":"9 Re-cleaning the G7 speeches","heading":"9.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"re-cleaning-the-g7-speeches.html","id":"filter-speeches-to-g7-countries-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.2 Filter speeches to G7 countries","text":"","code":"\ng7_members <- c(\"Canada\", \"France\", \"Germany\", \"Italy\", \"Japan\", \"United Kingdom\", \"United States\")\n\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-with-country\") %>%\n  filter(country %in% g7_members)"},{"path":"re-cleaning-the-g7-speeches.html","id":"fix-one-date-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.3 Fix one date","text":"one speech United States whose date December 2023, December 2024,\ncorpus goes January 2024.","code":"\ndata_update <- tribble(\n  ~doc, ~date,\n  \"r240109a\", ymd(\"2023-12-08\")\n)\n\nspeeches <- speeches %>%\n  rows_update(data_update, by=\"doc\")"},{"path":"re-cleaning-the-g7-speeches.html","id":"repairs-and-removals-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4 Repairs and removals","text":"","code":""},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-introductions-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4.1 Remove introductions","text":"Previously, introductory content gave brief description speech, along first\nsentence speech, removed. Now, first sentence speech removed \ngratitude word detected.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = if_else(\n      str_detect(first_sentence, pattern=\"(\\\\*\\\\s){3}\"),\n      if_else(\n        str_detect(first_sentence, pattern=\"(?i)thank|acknowledge|honou?r|grateful|pleas|welcome|delight\"),\n        str_remove(text, pattern=\"^[^.]+\\\\.\"),\n        str_remove(text, pattern=\"^.*(\\\\*\\\\s){3}\")\n      ),\n      str_remove(text, pattern=\"^[^.]+\\\\.\")\n    ),\n    text = str_squish(text)\n  )"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-section-headers","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4.2 Remove section headers","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(Introduction|Closing remarks|Conclusion) (?=[:upper:])\"))"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-references-section-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4.3 Remove references section","text":"general text cleaning function, found R/clean_by_country.R, applied remove \nreferences section concluding remarks commonly found among speeches.","code":"\nsource(here::here(\"R\", \"clean_by_country.R\"))\n\nspeeches <- speeches %>%\n  mutate(text = clean_general(text))"},{"path":"re-cleaning-the-g7-speeches.html","id":"miscellaneous-removals","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4.4 Miscellaneous removals","text":"Mentions \"BIS central bankers' speeches\" within speeches removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(?i)BIS central bankers' speeches\"))"},{"path":"re-cleaning-the-g7-speeches.html","id":"repair-typos-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4.5 Repair typos","text":"Repair potential typos Italy (appearing Italty).","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"Italty\", \"Italy\"))"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-mentions-of-own-institution-and-country","chapter":"9 Re-cleaning the G7 speeches","heading":"9.4.6 Remove mentions of own institution and country","text":"greater interest central bank mentions another central bank another country.\nTherefore, self-mentions bank, country, inhabitants removed. example, \nCanada, words remove include: Bank Canada, BoC, Canada, Canada's, Canadian. \nremoval patterns corresponding bank stored \ninst/data-misc/bank_country_regex_patterns.csv.","code":"\nbank_country_regex_patterns <- read_delim(\n  here::here(\"inst\", \"data-misc\", \"bank_country_regex_patterns.csv\"),\n  delim = \",\",\n  escape_backslash = TRUE\n) %>%\n  filter(country %in% g7_members) %>%\n  select(country, regex_pattern)\n\nspeeches <- speeches %>%\n  left_join(bank_country_regex_patterns, by=\"country\") %>%\n  mutate(text = str_remove_all(text, regex_pattern)) %>%\n  select(-regex_pattern)"},{"path":"re-cleaning-the-g7-speeches.html","id":"general-cleaning-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5 General cleaning","text":"","code":""},{"path":"re-cleaning-the-g7-speeches.html","id":"normalisation-of-covid-related-terms","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.1 Normalisation of COVID related terms","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)COVID|COVID19|COVID-19|coronavirus\", \"COVID\"))"},{"path":"re-cleaning-the-g7-speeches.html","id":"normalisation-of-select-ngrams-into-acronyms-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.2 Normalisation of select ngrams into acronyms","text":"\"Central Bank Digital Currency\" particular 4-gram interest can converted \nabbreviated form.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)Central Bank Digital Currency\", \"CBDC\"))"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-non-ascii-characters-emails-social-media-handles-and-links-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.3 Remove non-ascii characters, emails, social media handles, and links","text":"addition chunk code last line, links begin http,\nhttps, www, removed, e.g. google.ca.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"[:^ascii:]\"),\n    text = str_remove_all(text, \"([[:alnum:]_.\\\\-]+)?@[[:alnum:].\\\\-]+\"),\n    text = str_remove_all(text, \"https?://\\\\S+\"),\n    text = str_remove_all(text, \"www\\\\.\\\\S+\"),\n    text = str_remove_all(text, \"[A-Za-z]+\\\\.[A-Za-z]+(\\\\.[A-Za-z]+)*\")\n  )"},{"path":"re-cleaning-the-g7-speeches.html","id":"removereplace-stray-andor-excessive-punctuation","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.4 Remove/replace stray and/or excessive punctuation","text":"minor changes opting replacement punctuation sequences spaces, instead \nremoval.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(\\\\* )+\"),\n    text = str_replace_all(text, \"\\\\?|!\", \".\"),\n    text = str_remove_all(text, \",\"),\n    text = str_remove_all(text, \"\\\"\"),\n    text = str_replace_all(text, \"'{2,}\", \"'\"),\n    text = str_remove_all(text, \"\\\\B'(?=[:alpha:])\"),\n    text = str_remove_all(text, \"(?<=[:alpha:])'\\\\B\"),\n    text = str_remove_all(text, \"\\\\B'\\\\B\"),\n    text = str_replace_all(text, \"\\\\.{3}\", \".\"),\n    text = str_replace_all(text, \" \\\\. \", \" \"),\n    text = str_replace_all(text, \"-\", \" \"),\n    text = str_replace_all(text, \"_\", \" \"),\n    text = str_remove_all(text, \"\\\\(|\\\\)|\\\\{|\\\\}|\\\\[|\\\\]|\\\\||;|:|\\\\+\")\n  )"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-numerical-quantities-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.5 Remove numerical quantities","text":"References figures, slides, graphs removed, addition dollar signs, percent signs,\nnumerical quantities.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"\\\\$\"),\n    text = str_remove_all(text, \"%\"),\n    text = str_remove_all(text, \"[:digit:]+([.,]+[:digit:]+)*\"),\n    text = str_remove_all(text, \"(Figure|Slide|Graph) [:digit:]+\"),\n    text = str_remove_all(text, \"[:digit:]\")\n  )"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-excessive-whitespace","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.6 Remove excessive whitespace","text":"Excessive whitespace resulting previous replacements removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_squish(text))"},{"path":"re-cleaning-the-g7-speeches.html","id":"remove-unneeded-columns-1","chapter":"9 Re-cleaning the G7 speeches","heading":"9.5.7 Remove unneeded columns","text":"","code":"\nspeeches <- speeches %>%\n  select(-first_sentence)"},{"path":"re-cleaning-the-g7-speeches.html","id":"save-the-data-5","chapter":"9 Re-cleaning the G7 speeches","heading":"9.6 Save the data","text":"Writing data pin board:Making separate copy metadata well:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g7-cleaned\",\n    title = \"speeches for g7 countries, cleaned\"\n  )\nspeeches_metadata <- speeches %>%\n  select(doc, date, institution, country)\n\nspeeches_board %>%\n  pin_qsave(\n    speeches_metadata,\n    \"speeches-g7-metadata\",\n    title = \"metadata for g7 speeches\"\n  )"},{"path":"cleaning-the-g10-speeches.html","id":"cleaning-the-g10-speeches","chapter":"10 Cleaning the G10 speeches","heading":"10 Cleaning the G10 speeches","text":"G10 consists eleven countries: G7 countries, plus Belgium, Netherlands, Sweden, \nSwitzerland. cleaning process G10 speeches nearly identical used G7\nspeeches. notable difference addition countries, typos \nintroduced, require repair.","code":""},{"path":"cleaning-the-g10-speeches.html","id":"initialisation-9","chapter":"10 Cleaning the G10 speeches","heading":"10.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"cleaning-the-g10-speeches.html","id":"filter-speeches-to-g10-countries","chapter":"10 Cleaning the G10 speeches","heading":"10.2 Filter speeches to G10 countries","text":"","code":"\ng10_members <- c(\n  \"Canada\", \"France\", \"Germany\", \"Italy\", \"Japan\", \"United Kingdom\", \"United States\",\n  \"Belgium\", \"Netherlands\", \"Sweden\", \"Switzerland\"\n)\n\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-with-country\") %>%\n  filter(country %in% g10_members)"},{"path":"cleaning-the-g10-speeches.html","id":"fix-one-date-2","chapter":"10 Cleaning the G10 speeches","heading":"10.3 Fix one date","text":"one speech United States whose date December 2023, December 2024,\ncorpus goes January 2024.","code":"\ndata_update <- tribble(\n  ~doc, ~date,\n  \"r240109a\", ymd(\"2023-12-08\")\n)\n\nspeeches <- speeches %>%\n  rows_update(data_update, by=\"doc\")"},{"path":"cleaning-the-g10-speeches.html","id":"repairs-and-removals-2","chapter":"10 Cleaning the G10 speeches","heading":"10.4 Repairs and removals","text":"","code":""},{"path":"cleaning-the-g10-speeches.html","id":"remove-introductions-2","chapter":"10 Cleaning the G10 speeches","heading":"10.4.1 Remove introductions","text":"Previously, introductory content gave brief description speech, along first\nsentence speech, removed. Now, first sentence speech removed \ngratitude word detected.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = if_else(\n      str_detect(first_sentence, pattern=\"(\\\\*\\\\s){3}\"),\n      if_else(\n        str_detect(first_sentence, pattern=\"(?i)thank|acknowledge|honou?r|grateful|pleas|welcome|delight\"),\n        str_remove(text, pattern=\"^[^.]+\\\\.\"),\n        str_remove(text, pattern=\"^.*(\\\\*\\\\s){3}\")\n      ),\n      str_remove(text, pattern=\"^[^.]+\\\\.\")\n    ),\n    text = str_squish(text)\n  )"},{"path":"cleaning-the-g10-speeches.html","id":"remove-section-headers-1","chapter":"10 Cleaning the G10 speeches","heading":"10.4.2 Remove section headers","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(Introduction|Closing remarks|Conclusion) (?=[:upper:])\"))"},{"path":"cleaning-the-g10-speeches.html","id":"remove-references-section-2","chapter":"10 Cleaning the G10 speeches","heading":"10.4.3 Remove references section","text":"general text cleaning function, found R/clean_by_country.R, applied remove \nreferences section concluding remarks commonly found among speeches.","code":"\nsource(here::here(\"R\", \"clean_by_country.R\"))\n\nspeeches <- speeches %>%\n  mutate(text = clean_general(text))"},{"path":"cleaning-the-g10-speeches.html","id":"miscellaneous-removals-1","chapter":"10 Cleaning the G10 speeches","heading":"10.4.4 Miscellaneous removals","text":"Mentions \"BIS central bankers' speeches\" within speeches removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(?i)BIS central bankers' speeches\"))"},{"path":"cleaning-the-g10-speeches.html","id":"repair-typos-2","chapter":"10 Cleaning the G10 speeches","heading":"10.4.5 Repair typos","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_replace_all(text, \"Italty\", \"Italy\"),\n    text = str_replace_all(text, \"Riskbank|Risksbank\", \"Riksbank\"),\n    text = str_replace_all(text, \"Nederlandse\", \"Nederlandsche\")\n  )"},{"path":"cleaning-the-g10-speeches.html","id":"remove-mentions-of-own-institution-and-country-1","chapter":"10 Cleaning the G10 speeches","heading":"10.4.6 Remove mentions of own institution and country","text":"greater interest central bank mentions another central bank another country.\nTherefore, self-mentions bank, country, inhabitants removed. example, \nCanada, words remove include: Bank Canada, BoC, Canada, Canada's, Canadian. \nremoval patterns corresponding bank stored \ninst/data-misc/bank_country_regex_patterns.csv.","code":"\nbank_country_regex_patterns <- read_delim(\n  here::here(\"inst\", \"data-misc\", \"bank_country_regex_patterns.csv\"),\n  delim = \",\",\n  escape_backslash = TRUE\n) %>%\n  filter(country %in% g10_members) %>%\n  select(country, regex_pattern)\n\nspeeches <- speeches %>%\n  left_join(bank_country_regex_patterns, by=\"country\") %>%\n  mutate(text = str_remove_all(text, regex_pattern)) %>%\n  select(-regex_pattern)"},{"path":"cleaning-the-g10-speeches.html","id":"general-cleaning-2","chapter":"10 Cleaning the G10 speeches","heading":"10.5 General cleaning","text":"","code":""},{"path":"cleaning-the-g10-speeches.html","id":"normalisation-of-covid-related-terms-1","chapter":"10 Cleaning the G10 speeches","heading":"10.5.1 Normalisation of COVID related terms","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)COVID|COVID19|COVID-19|coronavirus\", \"COVID\"))"},{"path":"cleaning-the-g10-speeches.html","id":"normalisation-of-select-ngrams-into-acronyms-2","chapter":"10 Cleaning the G10 speeches","heading":"10.5.2 Normalisation of select ngrams into acronyms","text":"\"Central Bank Digital Currency\" particular 4-gram interest can converted \nabbreviated form.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)Central Bank Digital Currency\", \"CBDC\"))"},{"path":"cleaning-the-g10-speeches.html","id":"remove-non-ascii-characters-emails-social-media-handles-and-links-2","chapter":"10 Cleaning the G10 speeches","heading":"10.5.3 Remove non-ascii characters, emails, social media handles, and links","text":"addition chunk code last line, links begin http,\nhttps, www, removed, e.g. google.ca.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"[:^ascii:]\"),\n    text = str_remove_all(text, \"([[:alnum:]_.\\\\-]+)?@[[:alnum:].\\\\-]+\"),\n    text = str_remove_all(text, \"https?://\\\\S+\"),\n    text = str_remove_all(text, \"www\\\\.\\\\S+\"),\n    text = str_remove_all(text, \"[A-Za-z]+\\\\.[A-Za-z]+(\\\\.[A-Za-z]+)*\")\n  )"},{"path":"cleaning-the-g10-speeches.html","id":"removereplace-stray-andor-excessive-punctuation-1","chapter":"10 Cleaning the G10 speeches","heading":"10.5.4 Remove/replace stray and/or excessive punctuation","text":"minor changes opting replacement punctuation sequences spaces, instead \nremoval.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(\\\\* )+\"),\n    text = str_replace_all(text, \"\\\\?|!\", \".\"),\n    text = str_remove_all(text, \",\"),\n    text = str_remove_all(text, \"\\\"\"),\n    text = str_replace_all(text, \"'{2,}\", \"'\"),\n    text = str_remove_all(text, \"\\\\B'(?=[:alpha:])\"),\n    text = str_remove_all(text, \"(?<=[:alpha:])'\\\\B\"),\n    text = str_remove_all(text, \"\\\\B'\\\\B\"),\n    text = str_replace_all(text, \"\\\\.{3}\", \".\"),\n    text = str_replace_all(text, \" \\\\. \", \" \"),\n    text = str_replace_all(text, \"-\", \" \"),\n    text = str_replace_all(text, \"_\", \" \"),\n    text = str_remove_all(text, \"\\\\(|\\\\)|\\\\{|\\\\}|\\\\[|\\\\]|\\\\||;|:|\\\\+\")\n  )"},{"path":"cleaning-the-g10-speeches.html","id":"remove-numerical-quantities-2","chapter":"10 Cleaning the G10 speeches","heading":"10.5.5 Remove numerical quantities","text":"References figures, slides, graphs removed, addition dollar signs, percent signs,\nnumerical quantities.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"\\\\$\"),\n    text = str_remove_all(text, \"%\"),\n    text = str_remove_all(text, \"[:digit:]+([.,]+[:digit:]+)*\"),\n    text = str_remove_all(text, \"(Figure|Slide|Graph) [:digit:]+\"),\n    text = str_remove_all(text, \"[:digit:]\")\n  )"},{"path":"cleaning-the-g10-speeches.html","id":"remove-excessive-whitespace-1","chapter":"10 Cleaning the G10 speeches","heading":"10.5.6 Remove excessive whitespace","text":"Excessive whitespace resulting previous replacements removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_squish(text))"},{"path":"cleaning-the-g10-speeches.html","id":"remove-unneeded-columns-2","chapter":"10 Cleaning the G10 speeches","heading":"10.5.7 Remove unneeded columns","text":"","code":"\nspeeches <- speeches %>%\n  select(-first_sentence)"},{"path":"cleaning-the-g10-speeches.html","id":"save-the-data-6","chapter":"10 Cleaning the G10 speeches","heading":"10.6 Save the data","text":"Writing data pin board:Making separate copy metadata well:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g10-cleaned\",\n    title = \"speeches for g10 countries, cleaned\"\n  )\nspeeches_metadata <- speeches %>%\n  select(doc, date, institution, country)\n\nspeeches_board %>%\n  pin_qsave(\n    speeches_metadata,\n    \"speeches-g10-metadata\",\n    title = \"metadata for g10 speeches\"\n  )"},{"path":"cleaning-the-g20-speeches.html","id":"cleaning-the-g20-speeches","chapter":"11 Cleaning the G20 speeches","heading":"11 Cleaning the G20 speeches","text":"G20 consists twenty members: G7 countries, Argentina, Australia, Brazil, China, India,\nIndonesia, Mexico, Russia, Saudi Arabia, South Africa, South Korea, Turkiye, United Kingdom, \nUnited States, European Union. cleaning process G20 speeches nearly\nidentical used G7 G10 speeches. notable difference removal \nendings references section speeches, member-specific text removal functions \napplied general text removal function (see R/clean_by_country.R).","code":""},{"path":"cleaning-the-g20-speeches.html","id":"initialisation-10","chapter":"11 Cleaning the G20 speeches","heading":"11.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"cleaning-the-g20-speeches.html","id":"filter-speeches-to-g20-members","chapter":"11 Cleaning the G20 speeches","heading":"11.2 Filter speeches to G20 members","text":"","code":"\ng20_members <- c(\n  \"Argentina\", \"Australia\", \"Brazil\", \"Canada\", \"China\", \"France\", \"Germany\", \"India\", \"Indonesia\",\n  \"Italy\", \"Japan\", \"Mexico\", \"Russian Federation\", \"Saudi Arabia\", \"South Africa\",\n  \"Korea, Republic of\", \"Turkiye\", \"United Kingdom\", \"United States\", \"Other_ECB\"\n)\n\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-with-country\") %>%\n  filter(country %in% g20_members)"},{"path":"cleaning-the-g20-speeches.html","id":"fix-one-date-3","chapter":"11 Cleaning the G20 speeches","heading":"11.3 Fix one date","text":"one speech United States whose date December 2023, December 2024,\ncorpus goes January 2024.","code":"\ndata_update <- tribble(\n  ~doc, ~date,\n  \"r240109a\", ymd(\"2023-12-08\")\n)\n\nspeeches <- speeches %>%\n  rows_update(data_update, by=\"doc\")"},{"path":"cleaning-the-g20-speeches.html","id":"fix-incomplete-speech","chapter":"11 Cleaning the G20 speeches","heading":"11.4 Fix incomplete speech","text":"one speech ECB complete speech text. full speech text\nobtained speech's webpage, read \ninst/data-misc/r221027c.txt, replaced original speech text.","code":"\nr221027c_text <- read_file(here::here(\"inst\", \"data-misc\", \"r221027c.txt\")) %>%\n  str_replace_all(\"[:cntrl:]\", \" \") %>%\n  str_squish()\n\ndata_update <- tribble(\n  ~doc, ~text,\n  \"r221027c\", r221027c_text\n)\n\nspeeches <- speeches %>%\n  rows_update(data_update, by=\"doc\")"},{"path":"cleaning-the-g20-speeches.html","id":"repairs-and-removals-3","chapter":"11 Cleaning the G20 speeches","heading":"11.5 Repairs and removals","text":"","code":""},{"path":"cleaning-the-g20-speeches.html","id":"remove-introductions-3","chapter":"11 Cleaning the G20 speeches","heading":"11.5.1 Remove introductions","text":", first sentence speech removed gratitude word detected.\nOtherwise, brief speech description removed.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = if_else(\n      str_detect(first_sentence, pattern=\"(\\\\*\\\\s){3}\"),\n      if_else(\n        str_detect(first_sentence, pattern=\"(?i)thank|acknowledge|honou?r|grateful|pleas|welcome|delight\"),\n        str_remove(text, pattern=\"^[^.]+\\\\.\"),\n        str_remove(text, pattern=\"^.*(\\\\*\\\\s){3}\")\n      ),\n      str_remove(text, pattern=\"^[^.]+\\\\.\")\n    ),\n    text = str_squish(text)\n  )"},{"path":"cleaning-the-g20-speeches.html","id":"remove-section-headers-2","chapter":"11 Cleaning the G20 speeches","heading":"11.5.2 Remove section headers","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(Introduction|Closing remarks|Conclusion) (?=[:upper:])\"))"},{"path":"cleaning-the-g20-speeches.html","id":"remove-references-section-3","chapter":"11 Cleaning the G20 speeches","heading":"11.5.3 Remove references section","text":"references section concluding remarks removed using country-specific cleaning\nfunctions applying general cleaning function (see R/clean_by_country.R). members\nwhose speeches required specific cleaning function include Australia, China, Indonesia, Saudi\nArabia, South Korea, European Union.","code":"\nsource(here::here(\"R\", \"clean_by_country.R\"))\n\nspeeches <- speeches %>%\n  mutate(text = case_match(\n    country,\n    \"Australia\" ~ clean_australia(text),\n    \"China\" ~ clean_china(text),\n    \"Indonesia\" ~ clean_indonesia(text),\n    \"Saudi Arabia\" ~ clean_saudiarabia(text),\n    \"Korea, Republic of\" ~ clean_korea(text),\n    \"Other_ECB\" ~ clean_ecb(text),\n    .default = text\n  )) %>%\n  mutate(text = clean_general(text))"},{"path":"cleaning-the-g20-speeches.html","id":"miscellaneous-removals-2","chapter":"11 Cleaning the G20 speeches","heading":"11.5.4 Miscellaneous removals","text":"Mentions \"BIS central bankers' speeches\" within speeches removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(?i)BIS central bankers' speeches\"))"},{"path":"cleaning-the-g20-speeches.html","id":"repair-typos-3","chapter":"11 Cleaning the G20 speeches","heading":"11.5.5 Repair typos","text":"Sweden Netherlands part G20, Italy's typos required repair.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"Italty\", \"Italy\"))"},{"path":"cleaning-the-g20-speeches.html","id":"remove-mentions-of-own-institution-and-country-2","chapter":"11 Cleaning the G20 speeches","heading":"11.5.6 Remove mentions of own institution and country","text":"greater interest central bank mentions another central bank another country.\nTherefore, self-mentions bank, country, inhabitants removed. example, \nCanada, words remove include: Bank Canada, BoC, Canada, Canada's, Canadian. \nremoval patterns corresponding bank stored \ninst/data-misc/bank_country_regex_patterns.csv.","code":"\nbank_country_regex_patterns <- read_delim(\n  here::here(\"inst\", \"data-misc\", \"bank_country_regex_patterns.csv\"),\n  delim = \",\",\n  escape_backslash = TRUE\n) %>%\n  filter(country %in% g20_members) %>%\n  select(country, regex_pattern)\n\nspeeches <- speeches %>%\n  left_join(bank_country_regex_patterns, by=\"country\") %>%\n  mutate(text = str_remove_all(text, regex_pattern)) %>%\n  select(-regex_pattern)"},{"path":"cleaning-the-g20-speeches.html","id":"general-cleaning-3","chapter":"11 Cleaning the G20 speeches","heading":"11.6 General cleaning","text":"","code":""},{"path":"cleaning-the-g20-speeches.html","id":"normalisation-of-covid-related-terms-2","chapter":"11 Cleaning the G20 speeches","heading":"11.6.1 Normalisation of COVID related terms","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)COVID|COVID19|COVID-19|coronavirus\", \"COVID\"))"},{"path":"cleaning-the-g20-speeches.html","id":"normalisation-of-select-ngrams-into-acronyms-3","chapter":"11 Cleaning the G20 speeches","heading":"11.6.2 Normalisation of select ngrams into acronyms","text":"\"Central Bank Digital Currency\" particular 4-gram interest can converted \nabbreviated form.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)Central Bank Digital Currency\", \"CBDC\"))"},{"path":"cleaning-the-g20-speeches.html","id":"remove-non-ascii-characters-emails-social-media-handles-and-links-3","chapter":"11 Cleaning the G20 speeches","heading":"11.6.3 Remove non-ascii characters, emails, social media handles, and links","text":"addition chunk code last line, links begin http,\nhttps, www, removed, e.g. google.ca.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"[:^ascii:]\"),\n    text = str_remove_all(text, \"([[:alnum:]_.\\\\-]+)?@[[:alnum:].\\\\-]+\"),\n    text = str_remove_all(text, \"https?://\\\\S+\"),\n    text = str_remove_all(text, \"www\\\\.\\\\S+\"),\n    text = str_remove_all(text, \"[A-Za-z]+\\\\.[A-Za-z]+(\\\\.[A-Za-z]+)*\")\n  )"},{"path":"cleaning-the-g20-speeches.html","id":"removereplace-stray-andor-excessive-punctuation-2","chapter":"11 Cleaning the G20 speeches","heading":"11.6.4 Remove/replace stray and/or excessive punctuation","text":"minor changes opting replacement punctuation sequences spaces, instead \nremoval.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(\\\\* )+\"),\n    text = str_replace_all(text, \"\\\\?|!\", \".\"),\n    text = str_remove_all(text, \",\"),\n    text = str_remove_all(text, \"\\\"\"),\n    text = str_replace_all(text, \"'{2,}\", \"'\"),\n    text = str_remove_all(text, \"\\\\B'(?=[:alpha:])\"),\n    text = str_remove_all(text, \"(?<=[:alpha:])'\\\\B\"),\n    text = str_remove_all(text, \"\\\\B'\\\\B\"),\n    text = str_replace_all(text, \"\\\\.{3}\", \".\"),\n    text = str_replace_all(text, \" \\\\. \", \" \"),\n    text = str_replace_all(text, \"-\", \" \"),\n    text = str_replace_all(text, \"_\", \" \"),\n    text = str_remove_all(text, \"\\\\(|\\\\)|\\\\{|\\\\}|\\\\[|\\\\]|\\\\||;|:|\\\\+\")\n  )"},{"path":"cleaning-the-g20-speeches.html","id":"remove-numerical-quantities-3","chapter":"11 Cleaning the G20 speeches","heading":"11.6.5 Remove numerical quantities","text":"References figures, slides, graphs removed, addition dollar signs, percent signs,\nnumerical quantities.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"\\\\$\"),\n    text = str_remove_all(text, \"%\"),\n    text = str_remove_all(text, \"[:digit:]+([.,]+[:digit:]+)*\"),\n    text = str_remove_all(text, \"(Figure|Slide|Graph) [:digit:]+\"),\n    text = str_remove_all(text, \"[:digit:]\")\n  )"},{"path":"cleaning-the-g20-speeches.html","id":"remove-excessive-whitespace-2","chapter":"11 Cleaning the G20 speeches","heading":"11.6.6 Remove excessive whitespace","text":"Excessive whitespace resulting previous replacements removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_squish(text))"},{"path":"cleaning-the-g20-speeches.html","id":"remove-unneeded-columns-3","chapter":"11 Cleaning the G20 speeches","heading":"11.6.7 Remove unneeded columns","text":"","code":"\nspeeches <- speeches %>%\n  select(-first_sentence)"},{"path":"cleaning-the-g20-speeches.html","id":"save-the-data-7","chapter":"11 Cleaning the G20 speeches","heading":"11.7 Save the data","text":"Writing data pin board:Making separate copy metadata well:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g20-cleaned\",\n    title = \"speeches for g20 countries, cleaned\"\n  )\nspeeches_metadata <- speeches %>%\n  select(doc, date, institution, country)\n\nspeeches_board %>%\n  pin_qsave(\n    speeches_metadata,\n    \"speeches-g20-metadata\",\n    title = \"metadata for g20 speeches\"\n  )"},{"path":"cleaning-the-bis-speeches.html","id":"cleaning-the-bis-speeches","chapter":"12 Cleaning the BIS speeches","heading":"12 Cleaning the BIS speeches","text":"cleaning BIS speeches nearly identical G7 G10 text quite\nstandard.","code":""},{"path":"cleaning-the-bis-speeches.html","id":"initialisation-11","chapter":"12 Cleaning the BIS speeches","heading":"12.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"cleaning-the-bis-speeches.html","id":"filter-for-bis-speeches","chapter":"12 Cleaning the BIS speeches","heading":"12.2 Filter for BIS speeches","text":"","code":"\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-with-country\") %>%\n  filter(country == \"Other_BIS\")"},{"path":"cleaning-the-bis-speeches.html","id":"repairs-and-removals-4","chapter":"12 Cleaning the BIS speeches","heading":"12.3 Repairs and removals","text":"","code":""},{"path":"cleaning-the-bis-speeches.html","id":"remove-introductions-4","chapter":"12 Cleaning the BIS speeches","heading":"12.3.1 Remove introductions","text":", first sentence speech removed gratitude word detected.\nOtherwise, brief speech description removed.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = if_else(\n      str_detect(first_sentence, pattern=\"(\\\\*\\\\s){3}\"),\n      if_else(\n        str_detect(first_sentence, pattern=\"(?i)thank|acknowledge|honou?r|grateful|pleas|welcome|delight\"),\n        str_remove(text, pattern=\"^[^.]+\\\\.\"),\n        str_remove(text, pattern=\"^.*(\\\\*\\\\s){3}\")\n      ),\n      str_remove(text, pattern=\"^[^.]+\\\\.\")\n    ),\n    text = str_squish(text)\n  )"},{"path":"cleaning-the-bis-speeches.html","id":"remove-section-headers-3","chapter":"12 Cleaning the BIS speeches","heading":"12.3.2 Remove section headers","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(Introduction|Closing remarks|Conclusion) (?=[:upper:])\"))"},{"path":"cleaning-the-bis-speeches.html","id":"remove-references-section-4","chapter":"12 Cleaning the BIS speeches","heading":"12.3.3 Remove references section","text":"references concluding remarks can removed using clean_general() function.","code":"\nsource(here::here(\"R\", \"clean_by_country.R\"))\n\nspeeches <- speeches %>%\n  mutate(text = clean_general(text))"},{"path":"cleaning-the-bis-speeches.html","id":"miscellaneous-removals-3","chapter":"12 Cleaning the BIS speeches","heading":"12.3.4 Miscellaneous removals","text":"Mentions \"BIS central bankers' speeches\" within speeches removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"(?i)BIS central bankers' speeches\"))"},{"path":"cleaning-the-bis-speeches.html","id":"remove-mentions-of-own-institution-and-country-3","chapter":"12 Cleaning the BIS speeches","heading":"12.3.5 Remove mentions of own institution and country","text":"greater interest central bank mentions another central bank another country.\nTherefore, self-mentions bank, country, inhabitants removed. example, \nCanada, words remove include: Bank Canada, BoC, Canada, Canada's, Canadian. \nremoval patterns corresponding bank stored \ninst/data-misc/bank_country_regex_patterns.csv.","code":"\nbis_regex_pattern <- read_delim(\n  here::here(\"inst\", \"data-misc\", \"bank_country_regex_patterns.csv\"),\n  delim = \",\",\n  escape_backslash = TRUE\n) %>%\n  filter(country == \"Other_BIS\") %>%\n  pull(regex_pattern)\n\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, bis_regex_pattern))"},{"path":"cleaning-the-bis-speeches.html","id":"general-cleaning-4","chapter":"12 Cleaning the BIS speeches","heading":"12.4 General cleaning","text":"","code":""},{"path":"cleaning-the-bis-speeches.html","id":"normalisation-of-covid-related-terms-3","chapter":"12 Cleaning the BIS speeches","heading":"12.4.1 Normalisation of COVID related terms","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)COVID|COVID19|COVID-19|coronavirus\", \"COVID\"))"},{"path":"cleaning-the-bis-speeches.html","id":"normalisation-of-select-ngrams-into-acronyms-4","chapter":"12 Cleaning the BIS speeches","heading":"12.4.2 Normalisation of select ngrams into acronyms","text":"\"Central Bank Digital Currency\" particular 4-gram interest can converted \nabbreviated form.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)Central Bank Digital Currency\", \"CBDC\"))"},{"path":"cleaning-the-bis-speeches.html","id":"remove-non-ascii-characters-emails-social-media-handles-and-links-4","chapter":"12 Cleaning the BIS speeches","heading":"12.4.3 Remove non-ascii characters, emails, social media handles, and links","text":"addition chunk code last line, links begin http,\nhttps, www, removed, e.g. google.ca.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"[:^ascii:]\"),\n    text = str_remove_all(text, \"([[:alnum:]_.\\\\-]+)?@[[:alnum:].\\\\-]+\"),\n    text = str_remove_all(text, \"https?://\\\\S+\"),\n    text = str_remove_all(text, \"www\\\\.\\\\S+\"),\n    text = str_remove_all(text, \"[A-Za-z]+\\\\.[A-Za-z]+(\\\\.[A-Za-z]+)*\")\n  )"},{"path":"cleaning-the-bis-speeches.html","id":"removereplace-stray-andor-excessive-punctuation-3","chapter":"12 Cleaning the BIS speeches","heading":"12.4.4 Remove/replace stray and/or excessive punctuation","text":"minor changes opting replacement punctuation sequences spaces, instead \nremoval.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(\\\\* )+\"),\n    text = str_replace_all(text, \"\\\\?|!\", \".\"),\n    text = str_remove_all(text, \",\"),\n    text = str_remove_all(text, \"\\\"\"),\n    text = str_replace_all(text, \"'{2,}\", \"'\"),\n    text = str_remove_all(text, \"\\\\B'(?=[:alpha:])\"),\n    text = str_remove_all(text, \"(?<=[:alpha:])'\\\\B\"),\n    text = str_remove_all(text, \"\\\\B'\\\\B\"),\n    text = str_replace_all(text, \"\\\\.{3}\", \".\"),\n    text = str_replace_all(text, \" \\\\. \", \" \"),\n    text = str_replace_all(text, \"-\", \" \"),\n    text = str_replace_all(text, \"_\", \" \"),\n    text = str_remove_all(text, \"\\\\(|\\\\)|\\\\{|\\\\}|\\\\[|\\\\]|\\\\||;|:|\\\\+\")\n  )"},{"path":"cleaning-the-bis-speeches.html","id":"remove-numerical-quantities-4","chapter":"12 Cleaning the BIS speeches","heading":"12.4.5 Remove numerical quantities","text":"References figures, slides, graphs removed, addition dollar signs, percent signs,\nnumerical quantities.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"\\\\$\"),\n    text = str_remove_all(text, \"%\"),\n    text = str_remove_all(text, \"[:digit:]+([.,]+[:digit:]+)*\"),\n    text = str_remove_all(text, \"(Figure|Slide|Graph) [:digit:]+\"),\n    text = str_remove_all(text, \"[:digit:]\")\n  )"},{"path":"cleaning-the-bis-speeches.html","id":"remove-excessive-whitespace-3","chapter":"12 Cleaning the BIS speeches","heading":"12.4.6 Remove excessive whitespace","text":"Excessive whitespace resulting previous replacements removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_squish(text))"},{"path":"cleaning-the-bis-speeches.html","id":"remove-unneeded-columns-4","chapter":"12 Cleaning the BIS speeches","heading":"12.4.7 Remove unneeded columns","text":"","code":"\nspeeches <- speeches %>%\n  select(-first_sentence)"},{"path":"cleaning-the-bis-speeches.html","id":"save-the-data-8","chapter":"12 Cleaning the BIS speeches","heading":"12.5 Save the data","text":"Writing data pin board:Making separate copy metadata well:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-bis-cleaned\",\n    title = \"speeches for BIS, cleaned\"\n  )\nspeeches_metadata <- speeches %>%\n  select(doc, date, institution, country)\n\nspeeches_board %>%\n  pin_qsave(\n    speeches_metadata,\n    \"speeches-bis-metadata\",\n    title = \"metadata for BIS speeches\"\n  )"}]
