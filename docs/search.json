[{"path":"index.html","id":"analysis-of-central-bank-speeches","chapter":"Analysis of Central Bank Speeches","heading":"Analysis of Central Bank Speeches","text":"Placeholder text","code":""},{"path":"colophon.html","id":"colophon","chapter":"Colophon","heading":"Colophon","text":"","code":""},{"path":"colophon.html","id":"core-dependencies","chapter":"Colophon","heading":"Core dependencies","text":"Dependencies carry analysis.","code":"##  package     * version    date (UTC) lib source\n##  AzureAuth     1.3.3      2021-09-13 [1] CRAN (R 4.1.3)\n##  AzureStor     3.7.0      2022-05-25 [1] CRAN (R 4.1.3)\n##  cld2          1.2.4      2022-10-26 [1] CRAN (R 4.1.3)\n##  dplyr         1.1.4      2023-11-17 [1] CRAN (R 4.1.3)\n##  fs            1.5.2      2021-12-08 [1] CRAN (R 4.1.3)\n##  here          1.0.1      2020-12-13 [1] CRAN (R 4.1.3)\n##  lubridate     1.9.2      2023-02-10 [1] CRAN (R 4.1.3)\n##  pins          1.4.0      2024-10-07 [1] CRAN (R 4.1.3)\n##  pinsqs        0.0.0.9000 2024-11-26 [1] Github (adamoshen/pinsqs@8d8aa38)\n##  purrr         1.0.2      2023-08-10 [1] CRAN (R 4.1.3)\n##  readr         2.1.4      2023-02-10 [1] CRAN (R 4.1.3)\n##  readxl        1.4.2      2023-02-09 [1] CRAN (R 4.1.3)\n##  rstudioapi    0.17.0     2024-10-16 [1] CRAN (R 4.1.3)\n##  stringi       1.8.4      2024-05-06 [1] CRAN (R 4.1.3)\n##  stringr       1.5.0      2022-12-02 [1] CRAN (R 4.1.3)\n##  tibble        3.2.1      2023-03-20 [1] CRAN (R 4.1.3)\n##  tidytext      0.3.2      2021-09-30 [1] CRAN (R 4.1.3)\n##  topicmodels   0.2-14     2023-03-31 [1] CRAN (R 4.1.3)\n##  udpipe        0.8.11     2023-01-06 [1] CRAN (R 4.1.3)\n##  utf8          1.2.2      2021-07-24 [1] CRAN (R 4.1.3)\n## \n##  [1] C:/Users/Adam/Documents/R/win-library/4.1\n##  [2] C:/Program Files/R/R-4.1.3/library"},{"path":"colophon.html","id":"suggested-dependencies","chapter":"Colophon","heading":"Suggested dependencies","text":"Dependencies building book.","code":"##  package     * version date (UTC) lib source\n##  bookdown      0.26    2022-04-15 [1] CRAN (R 4.1.3)\n##  bslib         0.4.2   2022-12-16 [1] CRAN (R 4.1.3)\n##  desc          1.4.2   2022-09-08 [1] CRAN (R 4.1.3)\n##  downlit       0.4.4   2024-06-10 [1] CRAN (R 4.1.3)\n##  rmarkdown     2.19    2022-12-15 [1] CRAN (R 4.1.3)\n##  servr         0.24    2021-11-16 [1] CRAN (R 4.1.3)\n##  sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.1.3)\n## \n##  [1] C:/Users/Adam/Documents/R/win-library/4.1\n##  [2] C:/Program Files/R/R-4.1.3/library"},{"path":"data-setup.html","id":"data-setup","chapter":"1 Data setup","heading":"1 Data setup","text":"chapter, speeches obtained Dropbox (csv format), minor adjustments\napplied text author fields, data re-saved processing \nsubsequent chapters.","code":""},{"path":"data-setup.html","id":"initialisation","chapter":"1 Data setup","heading":"1.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"data-setup.html","id":"minor-adjustments-to-raw-data","chapter":"1 Data setup","heading":"1.2 Minor adjustments to raw data","text":"Read speeches Dropbox:Perform minor adjustments:Rename column processed_text simply text.Remove time component dates.Perform normalization text author names ASCII form.Encode utf-8.Remove excessive spaces text author fields.Fix select author names consistency.","code":"\nspeeches <- read_csv(\"~/boc_speeches/lda/iteration_04/speeches_processed.csv\")\nspeeches <- speeches %>%\n  rename(text = processed_text) %>%\n  mutate(\n    date = as_date(date),\n    text = stringi::stri_trans_general(text, \"Greek-Latin\"),\n    text = stringi::stri_trans_general(text, \"Latin-ASCII\"),\n    text = utf8::as_utf8(text),\n    text = str_squish(text),\n    author = stringi::stri_trans_general(author, \"Greek-Latin\"),\n    author = stringi::stri_trans_general(author, \"Latin-ASCII\"),\n    author = utf8::as_utf8(author),\n    author = str_squish(author)\n  ) %>%\n  mutate(\n    author = str_replace_all(author, \"Angelovska-Bezoska\", \"Angelovska-Bezhoska\"),\n    author = str_replace_all(author, \"Angelovska Bezhoska\", \"Angelovska-Bezhoska\"),\n    text = str_replace_all(text, \"Angelovska-Bezoska\", \"Angelovska-Bezhoska\"),\n    text = str_replace_all(text, \"Angelovska Bezhoska\", \"Angelovska-Bezhoska\")\n  )"},{"path":"data-setup.html","id":"save-the-data","chapter":"1 Data setup","heading":"1.3 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-raw\",\n    title = \"speeches from dropbox with minor tweaks\"\n  )"},{"path":"identifying-the-country-from-the-text.html","id":"identifying-the-country-from-the-text","chapter":"2 Identifying the country from the text","heading":"2 Identifying the country from the text","text":"chapter documents extraction institution giving speech. applicable, \ncountry associated institution can identified.","code":""},{"path":"identifying-the-country-from-the-text.html","id":"initialisation-1","chapter":"2 Identifying the country from the text","heading":"2.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(cld2)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"identifying-the-country-from-the-text.html","id":"load-the-data","chapter":"2 Identifying the country from the text","heading":"2.2 Load the data","text":"","code":"\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-raw\")"},{"path":"identifying-the-country-from-the-text.html","id":"perform-language-detection","chapter":"2 Identifying the country from the text","heading":"2.3 Perform language detection","text":"Speeches dominant language English, removed. 18,827 speeches, 18,813\n(99.93%) English 14 (0.7%) English.","code":"\nspeeches <- speeches %>%\n  mutate(lang_cld2 = detect_language(text)) %>%\n  filter(lang_cld2 == \"en\") %>%\n  select(-lang_cld2)"},{"path":"identifying-the-country-from-the-text.html","id":"get-country","chapter":"2 Identifying the country from the text","heading":"2.4 Get country","text":"identification speech countries can briefly summarised follows:Extract institution name regex patterns.unable extract anything, extracted institution incorrect, affiliation \nauthor manually identified Google-ing.Normalise central bank names according format listed \nBIS website.Using list, identify country bank name.method chosen instead looking mentions country names first sentence \nspeech many instances meeting location different country \naffiliation author.","code":""},{"path":"identifying-the-country-from-the-text.html","id":"extract-institution-by-regex-patterns","chapter":"2 Identifying the country from the text","heading":"2.4.1 Extract institution by regex patterns","text":"institutions/organizations extracted looking general pattern :\n[position] (|) [institution name] within first sentence speech. attempt \nextraction institution/organization follows:","code":"\nextract_pattern1 <- \"(?<=(?:Board of Governors|Governing Board|Executive Board|Chief Executive Officer) of the )[^[:punct:]]+\"\nextract_pattern2 <- \"(?<=(?:Governor|President|Chairman|Director|Executive|Manager|Directorate) of the )[^[:punct:]]+\"\nextract_pattern3 <- \"(?<=Governor of )[^[:punct:]]+\" # for Philippines\nextract_pattern4 <- \"(?:Central|Reserve) Bank of (?:[:upper:][:lower:]+\\\\s?)+\"\nextract_pattern5 <- \"Bank of (?:[:upper:][:lower:]+\\\\s?)+\"\nextract_pattern6 <- \"(?i)National Bank of Serbia|Swiss National Bank|Hong Kong Monetary Authority|Monetary Authority of Singapore|Banco de Espana|Banco de Portugal|Banco de Mexico|South African Reserve Bank|Sveriges Riksbank|Oesterreichische Nationalbank\"\nextract_pattern7 <- \"Federal Reserve System\"\nextract_pattern8 <- \"(?i)Bank of [:alpha:]+\"\n\nspeeches <- speeches %>%\n  mutate(\n    # Remove periods after salutations, initials, and credentials\n    text = str_remove_all(text, \"(?<=Mr|Ms|Mrs|PhD|Dr|Dott|Prof|Jr|Sig|\\\\bp|\\\\bm|\\\\ba|\\\\bh|\\\\bc|\\\\bmult|vs|[A-Z0-9])\\\\.\"),\n    text = str_replace_all(text, \"Member Board of Governors\", \"Member of the Board of Governors\"),\n    text = str_replace_all(text, \"Govenor\", \"Governor\"),\n    # Extract first sentence before looking for patterns.\n    first_sentence = str_extract(text, \"^[^.]+\\\\.\"),\n    institution = str_extract(first_sentence, extract_pattern1),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern2), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern3), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern4), institution),\n    institution = if_else(institution == \"People\", \"The People's Bank of China\", institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern5), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern6), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern7), institution),\n    institution = if_else(is.na(institution), str_extract(first_sentence, extract_pattern8), institution)\n  )"},{"path":"identifying-the-country-from-the-text.html","id":"fill-missingincorrect-institutions","chapter":"2 Identifying the country from the text","heading":"2.4.2 Fill missing/incorrect institutions","text":"extraction failed incorrect (determined looking institution values NA\nvalues low frequencies), speeches' institutions/organizations \nmanually determined Google-ing author speech. information stored \ninst/data-misc/author_affiliations.xlsx. data updated according spreadsheet (\napplicable).Two speeches remained missing values author institution. missing values \nfilled follows:","code":"\nauthor_affiliations <- read_xlsx(here::here(\"inst\", \"data-misc\", \"author_affiliations.xlsx\"))\n\nspeeches <- speeches %>%\n  rows_update(author_affiliations, by=\"author\")\nmissing_info <- tribble(\n  ~doc, ~author, ~institution,\n  \"r180725i\", \"Pablo Hernandez de Cos\", \"Bank of Spain\",\n  \"r180810b\", \"Jorgovanka Tabakovic\", \"National Bank of Serbia\"\n)\n\nspeeches <- speeches %>%\n  rows_update(missing_info, by=\"doc\")"},{"path":"identifying-the-country-from-the-text.html","id":"normalise-institution-names","chapter":"2 Identifying the country from the text","heading":"2.4.3 Normalise institution names","text":"list banks official names BIS website\ndownloaded stored inst/data-misc/bank_list.xlsx. extracted institution names \nprevious step normalised match names list. Additional organizations \nadded, BIS (Bank International Settlements) ECB (European Central Bank). US\nFederal Reserves associated common bank name Federal Reserve Bank.regex patterns , one may notice institution names contain typos, extracted\ndirectly speech text. Examples include Italy Italty Latvia Lativa. may\nimportant keep mind cleaning text later step.","code":"\nspeeches <- speeches %>%\n  mutate(\n    institution = str_squish(institution),\n    institution = case_when(\n      str_detect(institution, \"Federal Reserve|Atlanta|Chicago|Kansas City|New York|Saint Louis|San Francisco|America|BANK of NEW\") ~ \"Federal Reserve Bank\",\n      str_detect(institution, \"European Central Bank\") ~ \"European Central Bank\",\n      str_detect(institution, \"ECB\") ~ \"European Central Bank\",\n      str_detect(institution, \"Mauritius\") ~ \"Bank of Mauritius\",\n      str_detect(institution, \"Bundesbank\") ~ \"Deutsche Bundesbank\",\n      str_detect(institution, \"Italy|Italty\") ~ \"Bank of Italy\",\n      str_detect(institution, \"France\") ~ \"Bank of France\",\n      str_detect(institution, \"Japan\") ~ \"Bank of Japan\",\n      str_detect(institution, \"Korea\") ~ \"Bank of Korea\",\n      str_detect(institution, \"Bank of Papua New Guinea\") ~ \"Bank of Papua New Guinea\",\n      str_detect(institution, \"Bank of PNG\") ~ \"Bank of Papua New Guinea\",\n      str_detect(institution, \"(?i)Mexico\") ~ \"Bank of Mexico\",\n      str_detect(institution, \"China\") ~ \"The People's Bank of China\",\n      str_detect(institution, \"Ireland\") ~ \"Central Bank of Ireland\",\n      str_detect(institution, \"(?i)Portugal\") ~ \"Banco de Portugal\",\n      str_detect(institution, \"Bosnia|Herzegovina\") ~ \"Central Bank of Bosnia and Herzegovina\",\n      str_detect(institution, \"Romania\") ~ \"National Bank of Romania\",\n      str_detect(institution, \"Malaysia\") ~ \"Central Bank of Malaysia\",\n      str_detect(institution, \"Sierra Leone\") ~ \"Bank of Sierra Leone\",\n      str_detect(institution, \"Thailand\") ~ \"Bank of Thailand\",\n      str_detect(institution, \"(?i)Uganda\") ~ \"Bank of Uganda\",\n      str_detect(institution, \"Slovenia\") ~ \"Bank of Slovenia\",\n      str_detect(institution, \"Banka Slovenije\") ~ \"Bank of Slovenia\",\n      str_detect(institution, \"Bangko|Philippine|\\\\bBSP\\\\b\") ~ \"Central Bank of the Philippines (Bangko Sentral ng Pilipinas)\",\n      str_detect(institution, \"(?i)Riksbank\") ~ \"Sveriges Riksbank\",\n      str_detect(institution, \"Sweden|Swedish\") ~ \"Sveriges Riksbank\",\n      str_detect(institution, \"Riskbank|Risksbank\") ~ \"Sveriges Riksbank\",\n      str_detect(institution, \"Swiss\") ~ \"Swiss National Bank\",\n      str_detect(institution, \"Austria|Oesterreichische\") ~ \"Oesterreichische Nationalbank, the Austrian Central Bank\",\n      str_detect(institution, \"Norges|Norwegian\") ~ \"Central Bank of Norway\",\n      str_detect(institution, \"Denmark|Danmarks\") ~ \"Danmarks Nationalbank\",\n      str_detect(institution, \"Nederlandsche|Netherlands|Nederlandse\") ~ \"De Nederlandsche Bank\",\n      str_detect(institution, \"Macedonia\") ~ \"National Bank of the Republic of North Macedonia\",\n      str_detect(institution, \"Spain\") ~ \"Bank of Spain\",\n      str_detect(institution, \"Espana\") ~ \"Bank of Spain\",\n      str_detect(institution, \"(?i)Canada\") ~ \"Bank of Canada\",\n      str_detect(institution, \"(?i)Serbia\") ~ \"National Bank of Serbia\",\n      str_detect(institution, \"Hong Kong\") ~ \"Hong Kong Monetary Authority\",\n      str_detect(institution, \"India\") ~ \"Reserve Bank of India\",\n      str_detect(institution, \"Bangladesh\") ~ \"Bangladesh Bank\",\n      str_detect(institution, \"Indonesia\") ~ \"Bank Indonesia\",\n      str_detect(institution, \"Algeria\") ~ \"Bank of Algeria\",\n      str_detect(institution, \"Pakistan\") ~ \"State Bank of Pakistan\",\n      str_detect(institution, \"England\") ~ \"Bank of England\",\n      str_detect(institution, \"Finland\") ~ \"Bank of Finland\",\n      str_detect(institution, \"Suomen Pankki\") ~ \"Bank of Finland\",\n      str_detect(institution, \"(?i)Australia\") ~ \"Reserve Bank of Australia\",\n      str_detect(institution, \"Bahrain\") ~ \"Central Bank of Bahrain\",\n      str_detect(institution, \"Barbados\") ~ \"Central Bank of Barbados\",\n      str_detect(institution, \"Bahamas\") ~ \"Central Bank of The Bahamas\",\n      str_detect(institution, \"Belgium\") ~ \"National Bank of Belgium\",\n      str_detect(institution, \"(?i)Botswana\") ~ \"Bank of Botswana\",\n      str_detect(institution, \"Carribean\") ~ \"Eastern Caribbean Central Bank\",\n      str_detect(institution, \"(?i)Cambodia\") ~ \"National Bank of Cambodia\",\n      str_detect(institution, \"Chile\") ~ \"Central Bank of Chile\",\n      str_detect(institution, \"Columbia\") ~ \"Central Bank of Colombia\",\n      str_detect(institution, \"Croatia|Croation\") ~ \"Croatian National Bank\",\n      str_detect(institution, \"Curacao\") ~ \"Central Bank of Curacao and Sint Maarten\",\n      str_detect(institution, \"Cyprus\") ~ \"Central Bank of Cyprus\",\n      str_detect(institution, \"Czech\") ~ \"Czech National Bank\",\n      str_detect(institution, \"Ecuador\") ~ \"Central Bank of Ecuador\",\n      str_detect(institution, \"Eesti Pank\") ~ \"Bank of Estonia\",\n      str_detect(institution, \"(?i)Fiji\") ~ \"Reserve Bank of Fiji\",\n      str_detect(institution, \"Gambia\") ~ \"Central Bank of The Gambia\",\n      str_detect(institution, \"(?i)Ghana\") ~ \"Bank of Ghana\",\n      str_detect(institution, \"Greece\") ~ \"Bank of Greece\",\n      str_detect(institution, \"Guatemala\") ~ \"Bank of Guatemala\",\n      str_detect(institution, \"Hellenic\") ~ \"Bank of Greece\",\n      str_detect(institution, \"Iceland\") ~ \"Central Bank of Iceland\",\n      str_detect(institution, \"Kenya\") ~ \"Central Bank of Kenya\",\n      str_detect(institution, \"Kosovo\") ~ \"Central Bank of the Republic of Kosovo\",\n      str_detect(institution, \"Kuwait\") ~ \"Central Bank of Kuwait\",\n      str_detect(institution, \"Lativa\") ~ \"Bank of Latvia\",\n      str_detect(institution, \"Lithuania\") ~ \"Bank of Lithuania\",\n      str_detect(institution, \"Luxembourg\") ~ \"Central Bank of Luxembourg\",\n      str_detect(institution, \"Malawi\") ~ \"Reserve Bank of Malawi\",\n      str_detect(institution, \"Malta\") ~ \"Central Bank of Malta\",\n      str_detect(institution, \"Mozambique\") ~ \"Bank of Mozambique\",\n      str_detect(institution, \"Bank of Al\\\\b|Bank Al\\\\b|Al-Maghrib|Morocco\") ~ \"Bank Al-Maghrib (Central Bank of Morocco)\",\n      str_detect(institution, \"Nepal\") ~ \"Central Bank of Nepal (Nepal Rastra Bank)\",\n      str_detect(institution, \"New Zealand\") ~ \"Reserve Bank of New Zealand\",\n      str_detect(institution, \"Poland|Polski\") ~ \"Narodowy Bank Polski\",\n      str_detect(institution, \"Russia\") ~ \"Central Bank of the Russian Federation\",\n      str_detect(institution, \"Saudi\") ~ \"Saudi Central Bank\",\n      str_detect(institution, \"Seychelles\") ~ \"Central Bank of Seychelles\",\n      str_detect(institution, \"Singapore\") ~ \"Monetary Authority of Singapore\",\n      str_detect(institution, \"Slovakia|Slovenska\") ~ \"National Bank of Slovakia\",\n      str_detect(institution, \"Solomon Islands\") ~ \"Central Bank of Solomon Islands\",\n      str_detect(institution, \"South Africa\") ~ \"South African Reserve Bank\",\n      str_detect(institution, \"Ceylon\") ~ \"Central Bank of Sri Lanka\",\n      str_detect(institution, \"Swaziland|Eswatini\") ~ \"The Central Bank of Eswatini\",\n      str_detect(institution, \"Trinidad\") ~ \"Central Bank of Trinidad and Tobago\",\n      str_detect(institution, \"Tunisia\") ~ \"Central Bank of Tunisia\",\n      str_detect(institution, \"Turkiye|Turkey\") ~ \"Central Bank of the Republic of Turkiye\",\n      str_detect(institution, \"Emirates|UAE\") ~ \"Central Bank of the United Arab Emirates\",\n      str_detect(institution, \"Ukraine\") ~ \"National Bank of Ukraine\",\n      str_detect(institution, \"(?i)Zambia\") ~ \"Bank of Zambia\",\n      str_detect(institution, \"Bank for International Settlements|\\\\bBIS\\\\b\") ~ \"Bank for International Settlements\",\n      str_detect(institution, \"\\\\bBSC\\\\b\") ~ \"Banking Supervision Committee\",\n      str_detect(institution, \"Basel\") ~ \"Basel Committee\",\n      .default = institution\n    )\n  )"},{"path":"identifying-the-country-from-the-text.html","id":"get-country-from-institution-names","chapter":"2 Identifying the country from the text","heading":"2.4.4 Get country from institution names","text":"list banks, can associate speech country performing join.","code":"\nbank_list <- read_xlsx(here::here(\"inst\", \"data-misc\", \"bank_list.xlsx\"))\n\nspeeches <- speeches %>%\n  left_join(bank_list, by=\"institution\")"},{"path":"identifying-the-country-from-the-text.html","id":"save-the-data-1","chapter":"2 Identifying the country from the text","heading":"2.5 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-with-country\",\n    title = \"speeches with institutions and countries\"\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"cleaning-text-for-g7-countries","chapter":"3 Cleaning text for G7 countries","heading":"3 Cleaning text for G7 countries","text":"chapter documents cleaning text speeches given G7 country.","code":""},{"path":"cleaning-text-for-g7-countries.html","id":"initialisation-2","chapter":"3 Cleaning text for G7 countries","heading":"3.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"cleaning-text-for-g7-countries.html","id":"filter-speeches-to-g7-countries","chapter":"3 Cleaning text for G7 countries","heading":"3.2 Filter speeches to G7 countries","text":"","code":"\ng7_members <- c(\"Canada\", \"France\", \"Germany\", \"Italy\", \"Japan\", \"United Kingdom\", \"United States\")\n\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-with-country\") %>%\n  filter(country %in% g7_members)"},{"path":"cleaning-text-for-g7-countries.html","id":"fix-one-date","chapter":"3 Cleaning text for G7 countries","heading":"3.3 Fix one date","text":"one speech whose date December 2023, December 2024, corpus goes\nJanuary 2024.","code":"\ndata_update <- tribble(\n  ~doc, ~date,\n  \"r240109a\", ymd(\"2023-12-08\")\n)\n\nspeeches <- speeches %>%\n  rows_update(data_update, by=\"doc\")"},{"path":"cleaning-text-for-g7-countries.html","id":"repairs-and-removals","chapter":"3 Cleaning text for G7 countries","heading":"3.4 Repairs and removals","text":"","code":""},{"path":"cleaning-text-for-g7-countries.html","id":"remove-introductions","chapter":"3 Cleaning text for G7 countries","heading":"3.4.1 Remove introductions","text":"introductory remarks speech removed using pattern previously used \nidentify first sentence speech.\"Introduction\" headers also removed, identified presence word \"Introduction\"\ntitle case, followed another word title case.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove(text, pattern=\"^[^.]+\\\\.\"),\n    text = str_squish(text)\n  )\nspeeches <- speeches %>%\n  mutate(text = str_remove(text, \"Introduction (?=[:upper:])\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-references-section","chapter":"3 Cleaning text for G7 countries","heading":"3.4.2 Remove references section","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(?<=[:punct:]|[:digit:]) References:? .+$\"),\n    text = str_remove_all(text, \"References (?=[:upper:]).+$\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"repair-typos","chapter":"3 Cleaning text for G7 countries","heading":"3.4.3 Repair typos","text":"mentioned section normalising institution names, \ncountry names incorrectly entered require repair. G7 countries, Italy \none affected.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"Italty\", \"Italy\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-own-institution-and-country-names","chapter":"3 Cleaning text for G7 countries","heading":"3.4.4 Remove own institution and country names","text":"greater interest central bank mentions another central bank another country.\nTherefore, self-mentions bank, country, inhabitants removed. example, \nCanada, words remove include: Bank Canada, Canada, Canada's, Canadian. \nremoval patterns corresponding bank stored \ninst/data-misc/bank_country_regex_patterns.xlsx.","code":"\nbank_country_regex_patterns <- read_xlsx(\"inst/data-misc/bank_country_regex_patterns.xlsx\") %>%\n  filter(country %in% g7_members) %>%\n  select(country, regex_pattern)\n\nspeeches <- speeches %>%\n  left_join(bank_country_regex_patterns, by=\"country\") %>%\n  mutate(text = str_remove_all(text, regex_pattern)) %>%\n  select(-regex_pattern)"},{"path":"cleaning-text-for-g7-countries.html","id":"general-cleaning","chapter":"3 Cleaning text for G7 countries","heading":"3.5 General cleaning","text":"","code":""},{"path":"cleaning-text-for-g7-countries.html","id":"normalisaion-of-covid-related-terms","chapter":"3 Cleaning text for G7 countries","heading":"3.5.1 Normalisaion of COVID related terms","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)COVID|COVID19|COVID-19|coronavirus\", \"COVID\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"normalisation-of-select-ngrams-into-acronyms","chapter":"3 Cleaning text for G7 countries","heading":"3.5.2 Normalisation of select ngrams into acronyms","text":"\"Central Bank Digital Currency\" particular 4-gram interest can converted \nabbreviated form.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_replace_all(text, \"(?i)Central Bank Digital Currency\", \"CBDC\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-non-ascii-characters-emails-social-media-handles-and-links","chapter":"3 Cleaning text for G7 countries","heading":"3.5.3 Remove non-ascii characters, emails, social media handles, and links","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"[:^ascii:]\"),\n    text = str_remove_all(text, \"([[:alnum:]_.\\\\-]+)?@[[:alnum:]_.\\\\-]+\"),\n    text = str_remove_all(text, \"https?://\\\\S+\"),\n    text = str_remove_all(text, \"www\\\\.\\\\S+\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"removereplace-strayexcessive-punctuation","chapter":"3 Cleaning text for G7 countries","heading":"3.5.4 Remove/replace stray/excessive punctuation","text":"","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"(\\\\* )+\"),\n    text = str_replace_all(text, \"\\\\?|!\", \".\"),\n    text = str_remove_all(text, \",\"),\n    text = str_remove_all(text, \"\\\"\"),\n    text = str_replace_all(text, \"'{2,}\", \"'\"),\n    text = str_remove_all(text, \"\\\\B'(?=[:alpha:])\"),\n    text = str_remove_all(text, \"(?<=[:alpha:])'\\\\B\"),\n    text = str_remove_all(text, \"\\\\B'\\\\B\"),\n    text = str_replace_all(text, \"\\\\.{3}\", \".\"),\n    text = str_remove_all(text, \" \\\\. \"),\n    text = str_remove_all(text, \"-\"),\n    text = str_remove_all(text, \"_\"),\n    text = str_remove_all(text, \"\\\\(|\\\\)|\\\\{|\\\\}|\\\\[|\\\\]|\\\\||;|:|\\\\+\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-numerical-quantities","chapter":"3 Cleaning text for G7 countries","heading":"3.5.5 Remove numerical quantities","text":"included dollar signs, percent signs, punctuation separated numbers, whole numbers.","code":"\nspeeches <- speeches %>%\n  mutate(\n    text = str_remove_all(text, \"\\\\$\"),\n    text = str_remove_all(text, \"%\"),\n    text = str_remove_all(text, \"[:digit:]+([.,]+[:digit:]+)*\"),\n    text = str_remove_all(text, \"[:digit:]\")\n  )"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-stray-letters","chapter":"3 Cleaning text for G7 countries","heading":"3.5.6 Remove stray letters","text":"","code":"\nspeeches <- speeches %>%\n  mutate(text = str_remove_all(text, \"\\\\b[A-Za-z]\\\\b\"))"},{"path":"cleaning-text-for-g7-countries.html","id":"final-squish","chapter":"3 Cleaning text for G7 countries","heading":"3.5.7 Final squish","text":"Excessive whitespace resulting previous removals/replacements removed.","code":"\nspeeches <- speeches %>%\n  mutate(text = str_squish(text))"},{"path":"cleaning-text-for-g7-countries.html","id":"remove-unneeded-columns","chapter":"3 Cleaning text for G7 countries","heading":"3.5.8 Remove unneeded columns","text":"","code":"\nspeeches <- speeches %>%\n  select(-first_sentence)"},{"path":"cleaning-text-for-g7-countries.html","id":"save-the-data-2","chapter":"3 Cleaning text for G7 countries","heading":"3.6 Save the data","text":"Writing data pin board:Make separate copy metadata well:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g7-cleaned\",\n    title = \"speeches for g7 countries, cleaned\"\n  )\nspeeches_metadata <- speeches %>%\n  select(doc, date, institution, country)\n\nspeeches_board %>%\n  pin_qsave(\n    speeches_metadata,\n    \"speeches-g7-metadata\",\n    title = \"metadata for g7 speeches\"\n  )"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"identifying-important-bigrams-and-trigrams","chapter":"4 Identifying important bigrams and trigrams","heading":"4 Identifying important bigrams and trigrams","text":"chapter documents identification important bigrams trigrams following procedure\ndescribed Stephen Hansen, Michael McMahon, Andrea Prat1 John S. Justeson Slava M. Katz2.","code":""},{"path":"identifying-important-bigrams-and-trigrams.html","id":"initialisation-3","chapter":"4 Identifying important bigrams and trigrams","heading":"4.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(udpipe)\nlibrary(magrittr)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"tokenise-the-text-for-pos-tagging","chapter":"4 Identifying important bigrams and trigrams","heading":"4.2 Tokenise the text for POS-tagging","text":"text first tokenised sentences order create sentence identifier within\ndocuments. required later looking tag sequences, tag sequences span across\nsentences considered.text cast lowercase just yet, appeared affect tagging.Creating quick checkpoint:","code":"\nspeech_tokens <- speeches_board %>%\n  pin_qread(\"speeches-g7-cleaned\") %>%\n  select(doc, text) %>%\n  unnest_sentences(output=sentence, input=text, to_lower=FALSE) %>%\n  group_by(doc) %>%\n  mutate(sentence_id = 1:n()) %>%\n  ungroup() %>%\n  unnest_tokens(output=token, input=sentence, to_lower=FALSE)\nspeeches_board %>%\n  pin_qsave(\n    speech_tokens,\n    \"speeches-g7-tokens\",\n    title = \"tokens of speeches for g7 countries, cleaned\"\n  )"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"perform-the-pos-tagging","chapter":"4 Identifying important bigrams and trigrams","heading":"4.3 Perform the POS tagging","text":"","code":""},{"path":"identifying-important-bigrams-and-trigrams.html","id":"download-annotated-model","chapter":"4 Identifying important bigrams and trigrams","heading":"4.3.1 Download annotated model","text":"model used tagging \nUniversal Dependencies English GUM corpus.\nmodel included inst/data-misc folder, can downloaded calling \nfollowing:downloaded model can loaded follows:","code":"\nudpipe_download_model(language=\"english-gum\", model_dir=here::here(\"inst\", \"data-misc\"))\nenglish_gum <- udpipe_load_model(file = here::here(\"inst\", \"data-misc\", \"english-gum-ud-2.5-191206.udpipe\"))"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"tagging","chapter":"4 Identifying important bigrams and trigrams","heading":"4.3.2 Tagging","text":"udpipe_annotate():tokenizer = \"vertical\" indicates supplied text already tokenised form \ndata frame.parser = \"none\" indicates dependency parsing need performed.trace = 5e5 prints progress update every 5e5 tokens.supplying tokenised data frame, resulting output number rows. \n, sentence identifier speech_tokens can easily re-bound tagged tokens.Creating quick checkpoint:","code":"\ntags_gum <- speech_tokens %$%\n  udpipe_annotate(\n    object=english_gum, x=token, doc_id=doc,\n    tokenizer=\"vertical\", parser=\"none\", trace=5e5\n  ) %>%\n  as_tibble() %>%\n  select(doc_id, token, lemma, upos) %>%\n  rename(upos_gum = upos)\ntags_gum <- tags_gum %>%\n  bind_cols(\n    speech_tokens %>%\n      select(sentence_id)\n  ) %>%\n  select(doc_id, sentence_id, token, lemma, upos_gum)\nspeeches_board %>%\n  pin_qsave(\n    tags_gum,\n    \"gum-tagged-tokens-g7\",\n    title = \"gum tagged tokens of speeches for g7 countries\"\n  )"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"determine-bigrams-and-trigrams","chapter":"4 Identifying important bigrams and trigrams","heading":"4.4 Determine bigrams and trigrams","text":"Hansen, McMahon, Prat3, trigram sequences interest frequencies greater equal 50 :adjective - adjective - nounadjective - noun - nounnoun - adjective - nounnoun - noun - nounnoun - preposition - nounProper nouns treated nouns.Hansen, McMahon, Prat4, bigram sequences interest frequencies greater equal 100 :adjective - nounnoun - nounProper nouns treated nouns.","code":"\ntrigrams <- tags_gum %>%\n  select(-lemma) %>%\n  rename(token1=token, upos_gum1=upos_gum) %>%\n  group_by(doc_id, sentence_id) %>%\n  mutate(\n    token2 = lead(token1),\n    token3 = lead(token2),\n    upos_gum1 = if_else(upos_gum1 == \"PROPN\", \"NOUN\", upos_gum1),\n    upos_gum2 = lead(upos_gum1),\n    upos_gum3 = lead(upos_gum2)\n  ) %>%\n  ungroup() %>%\n  drop_na() %>%\n  select(token1, token2, token3, upos_gum1, upos_gum2, upos_gum3) %>%\n  unite(col=\"pos_pattern\", upos_gum1, upos_gum2, upos_gum3) %>%\n  filter(\n    str_detect(\n      pos_pattern,\n      \"ADJ_ADJ_NOUN|ADJ_NOUN_NOUN|NOUN_ADJ_NOUN|NOUN_NOUN_NOUN|NOUN_ADP_NOUN\"\n    )\n  ) %>%\n  count(token1, token2, token3, pos_pattern) %>%\n  filter(n >= 50) %>%\n  arrange(desc(n))\nbigrams <- tags_gum %>%\n  select(-lemma) %>%\n  rename(token1=token, upos_gum1=upos_gum) %>%\n  group_by(doc_id) %>%\n  mutate(\n    token2 = lead(token1),\n    upos_gum1 = if_else(upos_gum1 == \"PROPN\", \"NOUN\", upos_gum1),\n    upos_gum2 = lead(upos_gum1)\n  ) %>%\n  ungroup() %>%\n  drop_na() %>%\n  select(token1, token2, upos_gum1, upos_gum2) %>%\n  unite(col=\"pos_pattern\", upos_gum1, upos_gum2) %>%\n  filter(\n    str_detect(\n      pos_pattern,\n      \"ADJ_NOUN|NOUN_NOUN\"\n    )\n  ) %>%\n  count(token1, token2, pos_pattern) %>%\n  filter(n >= 100) %>%\n  arrange(desc(n))"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"prune-bigrams","chapter":"4 Identifying important bigrams and trigrams","heading":"4.4.1 Prune bigrams","text":"Bigrams whose frequencies fall required threshold consideration \nappearances trigrams removed. example, consider following n-gram counts:rising oil prices: 339falling oil prices: 275oil prices: 642Since bigram oil prices appears 642 - 339 - 275 = 28 times , meet\nbigram frequency threshold removed list bigrams.","code":"\ntrigram_token_counts <- trigrams %>%\n  select(token1, token2, token3, n)\n\nbigram_token_counts <- bigrams %>%\n  select(token1, token2, n)\n\nbigrams_to_remove <- bind_rows(\n  trigram_token_counts %>%\n    select(token1, token2, n) %>%\n    inner_join(bigram_token_counts, by=c(\"token1\", \"token2\"), suffix=c(\"_tri\", \"_bi\")\n  ),\n  trigram_token_counts %>%\n    select(token2, token3, n) %>%\n    rename(token1=token2, token2=token3) %>%\n    inner_join(bigram_token_counts, by=c(\"token1\", \"token2\"), suffix=c(\"_tri\", \"_bi\"))\n) %>%\n  group_by(token1, token2) %>%\n  summarise(\n    n_tri = sum(n_tri),\n    n_bi = unique(n_bi)\n  ) %>%\n  ungroup() %>%\n  mutate(n_diff = n_bi - n_tri) %>%\n  filter(n_diff < 100) %>%\n  select(token1, token2)\n\nbigrams <- anti_join(bigrams, bigrams_to_remove, by=c(\"token1\", \"token2\"))"},{"path":"identifying-important-bigrams-and-trigrams.html","id":"save-the-data-3","chapter":"4 Identifying important bigrams and trigrams","heading":"4.5 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    trigrams,\n    \"gum-trigrams-g7\",\n    title = \"gum trigrams from g7 speeches\"\n  )\n\nspeeches_board %>%\n  pin_qsave(\n    bigrams,\n    \"gum-bigrams-g7\",\n    title = \"gum bigrams from g7 speeches\"\n  )"},{"path":"incorporating-the-found-n-grams.html","id":"incorporating-the-found-n-grams","chapter":"5 Incorporating the found n-grams","heading":"5 Incorporating the found n-grams","text":"chapter documents incorporation previously found n-grams speech text.","code":""},{"path":"incorporating-the-found-n-grams.html","id":"initialisation-4","chapter":"5 Incorporating the found n-grams","heading":"5.1 Initialisation","text":"","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-g7-cleaned\")\n\nbigrams <- speeches_board %>%\n  pin_qread(\"gum-bigrams-g7\")\n\ntrigrams <- speeches_board %>%\n  pin_qread(\"gum-trigrams-g7\")"},{"path":"incorporating-the-found-n-grams.html","id":"text-replacement","chapter":"5 Incorporating the found n-grams","heading":"5.2 Text replacement","text":"identified n-grams replaced text via regex. str_replace_all() function allows\nmultiple replacements supplying named vector whose names regex patterns whose\nvalues replacements. regex patterns used case insensitive underscores \nadded words end n-gram prevent stemming (later stage). \naddition, trigrams replaced text bigrams ensure longest n-gram \ncaptured.","code":"\ntrigram_replacements <- trigrams %>%\n  mutate(across(c(token1, token2, token3), str_to_lower)) %>%\n  distinct(token1, token2, token3) %>%\n  mutate(\n    pattern = str_c(\"(?i)\\\\b\", token1, \" \", token2, \" \", token3, \"\\\\b\"),\n    replacement = str_c(token1, \"_\", token2, \"_\", token3, \"_\")\n  ) %>%\n  pull(replacement, name=pattern)\n\nbigram_replacements <- bigrams %>%\n  mutate(across(c(token1, token2), str_to_lower)) %>%\n  distinct(token1, token2) %>%\n  mutate(\n    pattern = str_c(\"(?i)\\\\b\", token1, \" \", token2, \"\\\\b\"),\n    replacement = str_c(token1, \"_\", token2, \"_\")\n  ) %>%\n  pull(replacement, name=pattern)\n\nspeeches <- speeches %>%\n  mutate(\n    text = str_replace_all(text, trigram_replacements),\n    text = str_replace_all(text, bigram_replacements)\n  )"},{"path":"incorporating-the-found-n-grams.html","id":"save-the-data-4","chapter":"5 Incorporating the found n-grams","heading":"5.3 Save the data","text":"Writing data pin board:","code":"\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"speeches-g7-with-ngrams\",\n    title = \"speeches for g7 countries, with ngrams\"\n  )"},{"path":"final-pre-processing.html","id":"final-pre-processing","chapter":"6 Final pre-processing","heading":"6 Final pre-processing","text":"chapter documents final pre-processing steps text can transformed \nrequired document-term matrices term-document matrices.","code":""},{"path":"final-pre-processing.html","id":"initialisation-5","chapter":"6 Final pre-processing","heading":"6.1 Initialisation","text":"list stop words used derived Snowball stop word lexicon, negation\nterms removed. code used obtain stop word list can found\n.","code":"\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(SnowballC)\nlibrary(pins)\nlibrary(pinsqs)\nlibrary(AzureStor)\n\nsource(here::here(\"R\", \"azure_init.R\"))\n\nspeeches_board <- storage_endpoint(\"https://cbspeeches1.dfs.core.windows.net/\", token=token) %>%\n  storage_container(name = \"cbspeeches\") %>%\n  board_azure(path = \"data-speeches\")\nspeeches <- speeches_board %>%\n  pin_qread(\"speeches-g7-with-ngrams\")\nnonneg_snowball <- read_rds(here::here(\"inst\", \"data-misc\", \"nonneg_snowball.rds\"))"},{"path":"final-pre-processing.html","id":"pre-processing","chapter":"6 Final pre-processing","heading":"6.2 Pre-processing","text":"usual pre-processing steps performed, including:Unnesting tokens. Lowercasing occurs step.Removal non-negative stop words.Stemming words.final check performed verify stemmed tokens spaces empty\nstrings, can result unusable models downstream.Making quick checkpoint:","code":"\nspeeches <- speeches %>%\n  unnest_tokens(output=word, input=text) %>%\n  anti_join(nonneg_snowball, by=\"word\") %>%\n  mutate(wordstem = wordStem(word))\nspeeches %>%\n  filter(wordstem == \" \")\n\nspeeches %>%\n  filter(stringi::stri_isempty(wordstem))\nspeeches_board %>%\n  pin_qsave(\n    speeches,\n    \"processed-speeches-g7\",\n    title = \"processed speeches for g7 countries. ready for dtm/tdm conversion.\"\n  )"},{"path":"final-pre-processing.html","id":"create-document-term-matrix","chapter":"6 Final pre-processing","heading":"6.3 Create document-term matrix","text":"document-term matrix required topic models via {topicmodels} package.","code":"\nspeeches_dtm <- speeches %>%\n  count(doc, wordstem) %>%\n  cast_dtm(doc, wordstem, n)\nspeeches_board %>%\n  pin_qsave(\n    speeches_dtm,\n    \"speeches-g7-dtm\",\n    title = \"dtm of speeches for g7 countries\"\n  )"},{"path":"final-pre-processing.html","id":"create-term-document-matrix","chapter":"6 Final pre-processing","heading":"6.4 Create term-document matrix","text":"term-document matrix (plain matrix) required NMF models.","code":"\nspeeches_tdm <- speeches %>%\n  count(doc, wordstem) %>%\n  cast_tdm(wordstem, doc, n) %>%\n  as.matrix()\nspeeches_board %>%\n  pin_qsave(\n    speeches_tdm,\n    \"speeches-g7-tdm\",\n    title = \"tdm of speeches for g7 countries\"\n  )"}]
